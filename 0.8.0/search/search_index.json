{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Metagenomics-Toolkit","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The Metagenomics-Toolkit or Toolkit for short is a scalable, data agnostic workflow that automates the analysis of short and long metagenomic reads obtained from Illumina or Oxford Nanopore Technology devices, respectively. The Toolkit offers not only standard features expected in a metagenome workflow, such as quality control, assembly, binning, and annotation, but also distinctive features, such as plasmid identification based on various tools, the recovery of unassembled microbial community members, and the discovery of microbial interdependencies through a combination of dereplication, cooccurrence, and genome-scale metabolic modeling. Furthermore, the Metagenomics-Toolkit includes a machine learning-optimized assembly step that tailors the peak RAM value requested by a metagenome assembler to match actual requirements, thereby minimizing the dependency on dedicated high-memory hardware.</p>"},{"location":"#schematic-overview","title":"Schematic Overview","text":"<p>The Toolkit can be applied in two steps which can be either applied in one execution or in two executions consecutively.  In addition, each module c0an be executed separately. </p>"},{"location":"#per-sample-pipeline-overview","title":"Per-Sample Pipeline Overview","text":"<p>The per-sample part of the pipeline processes each dataset individually. This step includes quality control, assembly, binning and annotation of  each dataset individually. You can read more at the getting started page.</p> <p></p>"},{"location":"#aggregation-pipeline-overview","title":"Aggregation Pipeline Overview","text":"<p>The aggregation part of the pipeline processes and combines the outputs of the \"per-sample\" part. MAGs of all input datasets are dereplicated and the abundances of the MAG representatives are estimated. The MAG representatives are then used for cooccurrence analyses.</p> <p></p>"},{"location":"#emgb","title":"EMGB","text":"<p>The Exploratory Metagenome Browser (EMGB) is a web interface that has been developed for the visual exploration of metagenomic datasets.  The majority of the Toolkit output including detected MAGs, MAG taxonomy, genes, pathways can be viewed via the Exploratory Metagenome Browser. Large datasets containing millions of genes and their annotations are pre-processed and visualized, to be searched in real-time by the user.  The platform provides access to different aspects of one or more datasets via an interactive taxonomic tree, a contig viewer, dynamic KEGG metabolic maps and different statistics.</p> <p></p>"},{"location":"#further-reading","title":"Further Reading","text":"<ul> <li> <p>If you are interested in testing the basic workflow, we recommend that you read the Quickstart page.</p> </li> <li> <p>In case you want to run the workflow on a cluster then you can skip the Quickstart page and start directly with the Getting Started section.</p> </li> <li> <p>If you want to run a specific module, then you can start with the modules section. </p> </li> </ul>"},{"location":"aggregation/","title":"Aggregation","text":"<p>There are two ways to execute the Toolkit. You can either run all steps in one execution, or run the per\u2010sample analysis (e.g., assembly, binning, annotation, etc.) first and then combine the results (e.g., via dereplication and co\u2010occurrence) in a second run. The second option allows you to process multiple samples via independent Toolkit executions on different infrastructures and combine all results afterwards.</p>"},{"location":"aggregation/#requirements","title":"Requirements","text":"<ol> <li>SLURM: The Toolkit was mainly developed for cloud-based clusters using SLURM as a resource orchestrator.</li> <li>Docker: Install Docker by following the official Docker installation instructions.</li> <li>Java: In order to run Nextflow, you need to install Java on your machine. This can be achieved via <code>sudo apt install default-jre</code>.</li> <li>Nextflow should be installed. Please check the official Nextflow instructions</li> <li>This tutorial assumes that you have already executed the Toolkit as described in the full pipeline section.</li> </ol>"},{"location":"aggregation/#run-the-toolkit","title":"Run the Toolkit","text":"<pre><code>NXF_HOME=$PWD/.nextflow NXF_VER=23.10.0 nextflow run metagenomics/metagenomics-tk \\\n    -work-dir $(pwd)/work \\\n    -profile slurm \\\n    -ansi-log false \\\n    -entry wAggregatePipeline \\\n    -params-file  https://raw.githubusercontent.com/metagenomics/metagenomics-tk/refs/heads/master/default/fullPipelineAggregate.yml \\\n    --logDir logAggregate \\\n    --s3SignIn false \\\n    --scratch /vol/scratch \\\n    --databases /vol/scratch/databases \\\n    --input my_data_spades_output \\\n    --output output\n</code></pre> <p>where</p> <ul> <li><code>-work-dir</code> points to a directory that is shared between multiple machines.</li> <li><code>-profile</code> defines the execution profile that should be used (local or cluster computing).</li> <li><code>-entry</code> is the entry point of the aggregation workflow.</li> <li><code>-params-file</code> sets the parameters file which defines the parameters for all tools. (see input section below)</li> <li><code>--logDir</code> points to a directory where your trace TSV, a timeline HTML of the executed processes and a report regarding the resource consumption of the workflow is saved.</li> <li><code>--s3SignIn</code> defines if any S3 login for retrieving inputs is necessary. See the S3 configuration section for more information on how to configure the Toolkit for possible S3 input data.</li> <li><code>--scratch</code> is the directory on the worker node where all intermediate results are saved.</li> <li><code>--databases</code> is the directory on the worker node where all databases are saved. Already downloaded databases on a shared file system can be configured in the database setting of the corresponding database section in the configuration file.</li> <li><code>--output</code> is the output directory where all results are saved. If you want to know more about which outputs are created, then please refer to the modules section.</li> <li><code>--input</code> points to the output directory of the per-sample workflow.</li> </ul> <p>Parameter override</p> <p>Any parameters defined with a double dash are parameters that override parameters that are already specified in the YAML file.</p>"},{"location":"aggregation/#input","title":"Input","text":"Configuration File <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: true\noutput: \"output\"\ninput: \"fullPipelineOutput\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  dereplication:\n    bottomUpClustering:\n      # stricter MIMAG medium quality\n      minimumCompleteness: 50\n      maximumContamination: 5\n      ANIBuffer: 20\n      mashBuffer: 2000\n      method: 'ANI'\n      additionalParams:\n        mash_sketch: \"\"\n        mash_dist: \"\"\n        # cluster cutoff\n        cluster: \" -c 0.05 \"\n        pyani: \" -m ANIb \"\n        representativeAniCutoff: 0.95\n  readMapping:\n    bwa2:\n      additionalParams:\n        bwa2_index: \"\"\n        bwa2_mem: \"\"\n     # This module produces two abundance tables.\n     # One table is based on relative abundance and the second one on the trimmed mean.\n     # Just using relative abundance makes it difficult to tell if a genome is part of a dataset.\n     # Thats why it makes sense to set at leat a low min covered fraction parameter.\n    coverm: \" --min-covered-fraction 80  --min-read-percent-identity 95 --min-read-aligned-percent 95 \"\n    covermONT: \" --min-covered-fraction 80  --min-read-aligned-percent 95 \"\n    minimap:\n      additionalParams:\n        minimap_index: \"\"\n        minimap: \"\"\n  cooccurrence:\n    inference:\n      additionalParams:\n        method: 'correlation'\n        rscript: \" --mincovthreshold 0.9 --maxzero 60 --minweight 0.4 \"\n        timeLimit: \"AUTO\"\n    metabolicAnnotation:\n      additionalParams:\n        metabolicEdgeBatches: 5\n        metabolicEdgeReplicates: 10\n        smetana: \" --flavor bigg --molweight \"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre>"},{"location":"aggregation/#output","title":"Output","text":"<p>The meaning of the produced output can be inspected on the respective module page. You can check for the results in the <code>AGGREGATED</code> folder:</p> <p>For example you could check for the number of species clusters created through dereplication:</p> <pre><code>cat  my_data_spades_output/AGGREGATED/1/dereplication/*/bottomUpClustering/clusters/clusters.tsv\n</code></pre> <p>Parameter override</p> <p>Please note that the dereplication method produces more meaningful results when more than one sample is provided as input.</p>"},{"location":"aggregation/#further-reading","title":"Further Reading","text":"<ul> <li> <p>Pipeline Configuration: If you want to configure and optimize the Toolkit for your data or your infrastructure then you can continue with the configuration section.</p> </li> <li> <p>In case you want to import the output to EMGB, please go on to the EMGB configuration section. Please keep in mind that for EMGB only the per-sample part is necessary.</p> </li> <li> <p>You might want to adjust the resource requirements of the Toolkit to your infrastructure.</p> </li> </ul>"},{"location":"configuration/","title":"Global Pipeline Configuration","text":""},{"location":"configuration/#global-parameter-settings","title":"Global parameter settings","text":"<ul> <li> <p><code>tempdir</code>: Temporary directory for storing files that are used to collect intermediate files.</p> </li> <li> <p><code>summary</code>: If true a summary folder is created storing results of all samples combined.</p> </li> <li> <p><code>output</code>: Output directory for storing pipeline results. If an S3 bucket is specified with the corresponding S3 credentials (See S3 configuration section) then    the output is written to S3.</p> </li> <li> <p><code>runid</code>: The run ID will be part of the output path and allows to distinguish between different pipeline configurations that were used for the same dataset.</p> </li> <li> <p><code>logDir</code>: A path to a directory which is used to store log files.</p> </li> <li> <p><code>scratch</code>: The scratch value can be either <code>false</code> or a path on a worker node. If a path is set, then the nextflow process in <code>slurm</code> mode is executed on the provided path.     If the standard mode is used, then the parameter is ignored.</p> </li> <li> <p><code>steps</code>: Steps allows to specify multiple pipeline modules for running the toolkit. We distinguish between two modes. You can either run one tool of    the pipeline or the whole pipeline with different configurations.</p> </li> <li> <p><code>databases</code>: This parameter specifies a place where files are downloaded to. If the <code>slurm</code> profile is used and databases should be downloaded, the path should point to a folder      which is not shared between the worker nodes (to reduce I/O on the shared folder resulting in a better performance). If this parameter is provided, the toolkit will create the specified     directory. If all your databases have already been extracted beforehand, you can simply omit this parameter.</p> </li> <li> <p><code>publishDirMode</code>: (optional) Per default results are symlinked to the chosen <code>output</code> directory. This default mode can be changed with this parameter.     A useful mode is \"copy\", to copy results instead of just linking them. Other modes to choose from here.  </p> </li> <li> <p><code>skipVersionCheck</code>: The toolkit is regurarly tested against a set of Nextflow versions. Setting the <code>--skipVersionCheck</code> allows you to use the toolkit with Nextflow versions    that were not tested.</p> </li> <li> <p><code>s3SignIn</code>: If your input data (not the databases) is not publicly accessible via S3, then you will have to set the <code>s3SignIn</code> parameter to <code>true</code>.</p> </li> </ul>"},{"location":"configuration/#s3-configuration","title":"S3 Configuration","text":"<p>All module inputs and outputs can be used in conjunction with S3. If you want to set a custom S3 configuration setting (i.e. custom S3 endpoint), you will have to modify the aws client parameters  with \" -c \".</p> <p>Example: <pre><code>aws {\n\n    client {\n\n      s3PathStyleAccess = true\n      connectionTimeout = 120000\n      maxParallelTransfers = 28 \n      maxErrorRetry = 10\n      protocol = 'HTTPS'\n      connectionTimeout = '2000'\n      endpoint = 'https://openstack.cebitec.uni-bielefeld.de:8080'\n      signerOverride = 'AWSS3V4SignerType'\n    }\n}\n</code></pre></p> <p>In addition you will have to set a Nextflow Secret with the following keys:</p> <pre><code>nextflow secrets set S3_ACCESS xxxxxxxxx\nnextflow secrets set S3_SECRET xxxxxxxxx\n</code></pre> <p><code>S3_ACCESS</code> corresponds to the aws S3 access key id and <code>S3_SECRET</code> is the aws S3 secret key. If your input data (not the databases) is publicly available then you have to set <code>s3SignIn:</code> to <code>false</code> in your config file. Please note that for using databases you have to set additional credentials (see database section). </p>"},{"location":"configuration/#configuration-of-computational-resources-used-for-pipeline-runs","title":"Configuration of Computational Resources used for Pipeline Runs","text":"<p>The toolkit uses the following machine types (flavors) for running tools. All flavors can be optionally adjusted by modifying the cpus and memory (in GB) parameters. If for example the largest flavor is not available in the infrastructure, <code>cpus</code> and <code>memory</code> parameters can be modified to fit the highmemMedium flavor. If larger flavors are available, it makes especially sense to increase the <code>cpus</code> and <code>memory</code> values of the <code>large</code> flavor to speed up for example assembly and read mapping.</p> <p>Example Configuration:</p> <pre><code>resources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>Additional flavors can be defined that can be used by methods that dynamically compute resources on tool error (for example the assembly module).</p> <p>Example:</p> <pre><code>resources:\n  xlarge:\n    cpus: 56\n    memory: 512\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>The full pipeline mode is able to predict the memory consumption of some assemblers (see assembly module). The prediction will also consider additional flavors which have been added to the resources section in the configuration file.</p>"},{"location":"database/","title":"Database Configuration","text":""},{"location":"database/#database-input-configuration","title":"Database input configuration","text":"<p>Whenever a database field can be specified as part of the tool configuration (such as in gtdb or checkm), you are able to provide different methods to fetch the database. In all settings, please make sure that the file has the same ending (e.g. .zip, .tar.gz) as specified in the corresponding tool section. In addition, as database names are used to name results with which they were created, said database names should contain the respective database number or date of creation. With this every result can be linked to one exact database version to clarify results.  Except for the <code>extractedDBPath</code> parameter, all other input types (https, s3,...) will download the database to the folder specified in the <code>database</code> parameter.</p>"},{"location":"database/#extracted-database-path","title":"Extracted Database Path","text":"<p>If you have already downloaded and extracted the database, you can specify the path using the <code>extractedDBPath</code> parameter. This setting is available in standard and slurm mode. In slurm mode the path can point to a db on the worker node.</p> <p>Example: <pre><code>database:\n  extractedDBPath: /vol/spool/gtdb/release202\n</code></pre></p>"},{"location":"database/#https-download","title":"HTTPS Download","text":"<p>The toolkit is able to download and extract the database, as long as the file ending equals the one specified in the corresponding tool section (.zip, tar.gz, tar.zst) This setting is available in standard and slurm mode. </p> <p>Example: <pre><code>database:\n  download:\n    source: 'https://openstack.cebitec.uni-bielefeld.de:8080/databases/gtdb.tar.gz'\n    md5sum: 77180f6a02769e7eec6b8c22d3614d2e \n</code></pre></p>"},{"location":"database/#local-file-path","title":"Local File Path","text":"<p>This setting allows you to reuse an already downloaded database. </p> <p>Example: <pre><code>database:\n  download:\n    source: '/vol/spool/gtdb.tar.gz'\n    md5sum: 77180f6a02769e7eec6b8c22d3614d2e \n</code></pre></p>"},{"location":"database/#s3-download","title":"S3 Download","text":"<p>You can specify an S3 link and configure the S3 call via the <code>s5cmd.params parameter. The</code>s5cmd.params` parameter allows you to set any setting available of the s5cmd commandline tool.  If you need credentials to access your databases, you can set them via the Nextflow secrets mechanism. The correct key name for the access and secret key can be found in the corresponding database section.</p> <p>In the following example the compressed file will be downloaded and extracted.</p> <p>Example for publicly available compressed database: <pre><code>database:\n  download:\n    source: 's3://databases/gtdb.tar.gz'\n    md5sum: 77180f6a02769e7eec6b8c22d3614d2e \n    s5cmd:\n      params: '--retry-count 30 --no-sign-request --no-verify-ssl --endpoint-url https://openstack.cebitec.uni-bielefeld.de:8080'\n</code></pre></p> <p>If your database is already extracted and available via S3, you can specify the S3 link using a wildcard as in the next example.</p> <pre><code>database:\n  download:\n    source: 's3://databases/gtdb/*'\n    md5sum: 77180f6a02769e7eec6b8c22d3614d2e \n    s5cmd:\n      params: '--retry-count 30 --no-verify-ssl --endpoint-url https://openstack.cebitec.uni-bielefeld.de:8080'\n</code></pre>"},{"location":"database/#updating-database-md5sums","title":"Updating Database MD5SUMs","text":"<p>The md5sum is computed over all md5sums of all files of the extracted database. If you need to update the md5sum because you updated your database you have to download the database  and run the following command</p> <pre><code>find /path/to/db -type f -exec md5sum {} \\; | sort | cut -d ' ' -f 1 | md5sum | cut -d ' ' -f 1\n</code></pre>"},{"location":"database/#database-download-strategy","title":"Database Download strategy","text":"<p>The toolkit allows to download databases on multiple nodes and tries to synchronize the download process between multiple jobs on a node. However not all possible combinations of profiles and download types are reasonable.</p> PROFILE Download to Shared NFS Download to worker database directory Reuse extracted directory STANDARD SLURM   On a disk local to the worker and nfs directory"},{"location":"developer_guidelines/","title":"Guidelines","text":""},{"location":"developer_guidelines/#commit-and-release-guidelines","title":"Commit and Release Guidelines","text":"<p>We are using git-chglog to automatically generate a changelog for the latest released based on our commit messages. Commit messages should follow the following format:</p> <pre><code>feat(scope): feature added in the scope\n</code></pre> <p>Example:</p> <pre><code>feat(assembly): megahit added\n</code></pre> <p><code>feat</code> can be replaced by one of the formats specified in the options sections of the config file (see example below). Scope can for example represent a module, a configuration or a specific document.</p> <p>A new release should be made the following way: </p> <ol> <li> <p>Checkout the dev branch.</p> </li> <li> <p>Update pipeline version in the nextflow manifest <code>nextflow.config</code>.</p> </li> <li> <p>Push the changes to the dev branch.</p> </li> <li> <p>Checkout the master branch.</p> </li> <li> <p>Merge the dev branch into the master branch. (<code>git merge dev</code>)</p> </li> <li> <p>Push the merged branch to the master branch.</p> </li> <li> <p>Create a release on Github based on the master branch.</p> </li> <li> <p>Run <code>git fetch</code> on the master branch to get the latest tag.</p> </li> <li> <p>Run <code>make changelog</code> and paste the output on the Github release section.</p> </li> <li> <p>Once the Github release is created, publish the wiki with newest tag.(see wiki section)</p> </li> </ol> <pre><code>style: github\ntemplate: CHANGELOG.tpl.md\ninfo:\n  title: CHANGELOG\n  repository_url: https://github.com/pbelmann/meta-omics-toolkit\noptions:\n  commits:\n    filters:\n      Type:\n        - feat\n        - fix\n        - refactor\n        - doc\n  commit_groups:\n    title_maps:\n      feat: Features\n      fix: Bug Fixes\n      refactor: Code Refactoring\n      doc: Documentation\n  header:\n    pattern: \"^(\\\\w*)(?:\\\\(([\\\\w\\\\$\\\\.\\\\-\\\\*\\\\s]*)\\\\))?\\\\:\\\\s(.*)$\"\n    pattern_maps:\n      - Type\n      - Scope\n      - Subject\n</code></pre>"},{"location":"developer_guidelines/#versioning","title":"Versioning","text":"<p>Following semantic versioning, we define the configuration input file and the output folder structure as our public <code>API</code>. Changes to the version numbers reflect updates to the config or the output folders and files. The toolkit consists of many modules that can be used in different combinations and because of this flexibility, we had to come up with a detailed versioning system. We version each module separately, as well as the pipeline itself.</p> <p>Module MAJOR version numbers are updated when a module-specific input parameter is updated or the output folder or file structure is changed. All module version numbers can be retrieved by running the toolkit with the <code>wGetModuleVersion</code> entry point and should be reported on the release page. </p> <p>The module version number is incorporated in the output directory (see output specification)  for easier parsing of the output directory. In the following we give examples when to increment which part of the version identifier:</p> <p>Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ul> <li>MAJOR version when you make incompatible changes, as for example modifying the output structure. A script that was build to parse the output structure must be adapted then.</li> <li>MINOR version when you add functionality in a backward compatible manner. One example is adding an additional tool to the module. </li> <li>PATCH version when you make backwards compatible bug fixes. This is necessary when you for example increment the docker container version number that fixes a bug or increases the     speed of the tool.</li> </ul> <p>The pipeline specific version number defined in the manifest part of the nextflow.config should be changed if either any module specific version number is incremented or any module-independent parameter (e.g. <code>tempdir</code>) or output structure is changed. </p>"},{"location":"developer_guidelines/#testing","title":"Testing","text":"<p>Tests for local use are specified in the <code>scripts</code> folder. These scripts are also used as part of the continuous integration tests. If you want to run these scripts locally, you will have to override the paths to the databases you have downloaded:</p> <p>Examples: <pre><code>bash scripts/test_fullPipeline.sh  \" --steps.magAttributes.checkm.database=/vol/spool/checkm --steps.magAttributes.gtdb.database=/vol/spool/gtdb/release202 \"\nbash scripts/test_fragmentRecruitment.sh  \" --steps.fragmentRecruitment.frhit.genomes=test/bins/small/bin.*.fa --steps.fragmentRecruitment.frhit.samples=test/reads/small/reads.tsv \"\nbash scripts/test_dereplication.sh \"  --steps.dereplication.pasolli.input=test/bins/small/attributes.tsv \"\nbash scripts/test_magAttributes.sh \"  --steps.magAttributes.input=test/bins/small/attributes.tsv \"\n</code></pre></p>"},{"location":"developer_guidelines/#nextflow-versions","title":"Nextflow Versions","text":"<p>The toolkit is tested against the lowest and highest Nextflow version number specified in VERSIONS.txt.</p>"},{"location":"developer_guidelines/#modules","title":"Modules","text":"<p>Functionality is structured in modules (assembly, binning, dereplication, .etc). Each module can have multiple workflows. Every module follows the output definition specified in the output specification  document. The name and the version of the module is specified in the <code>modules</code> section of the <code>nextflow.config</code> file.</p>"},{"location":"developer_guidelines/#workflows","title":"Workflows","text":"<ol> <li> <p>Worfklow names that can not be used directly and are just meant for internal use should start with an underscore.</p> </li> <li> <p>At least every workflow that can be used by other external workflows should contain a short description of the functionality. </p> </li> <li> <p>Workflow names must start with <code>w</code>. </p> </li> </ol>"},{"location":"developer_guidelines/#process","title":"Process","text":"<p>Process names should start <code>p</code>. The in- and output of processes should contain a sample and/or a bin and contig id. Custom error strategies that do not follow the strategy defined in nextflow.config, should be documented (see Megahit example).</p>"},{"location":"developer_guidelines/#processes-should-publish-process-specific-files","title":"Processes should publish process specific files","text":"<p>Processes should publish <code>.command.sh</code>, <code>.command.out</code>, <code>.command.log</code> and <code>.command.err</code> files but never <code>.command.run</code>. In cases where processes process different data but publish it to the same folder these files would be overwritten on every run. For example when Prokka publishes log files of every genome to the same sample directory. For that reason these files need to be renamed, so that their names include a unique id (e.g. bin id).  Please output those files to channel with the following entries and connect this channel to the pDumpLogs process that you can import from the utils module:</p> <pre><code>include { pDumpLogs } from '../utils/processes'\n\n...\n\ntuple env(FILE_ID), val(\"${output}\"), val(params.LOG_LEVELS.INFO), file(\".command.sh\"), \\\n        file(\".command.out\"), file(\".command.err\"), file(\".command.log\"), emit: logs\n</code></pre> <p>Examples can be viewed in the Checkm and Prokka process.</p>"},{"location":"developer_guidelines/#logs","title":"Logs","text":"<p>Log files should be stored in the user provided <code>logDir</code> directory.</p>"},{"location":"developer_guidelines/#log-level","title":"Log Level","text":"<p>Every configuration file must have a <code>logLevel</code> attribute that can have the following values:</p> <pre><code>ALL = 0  All logs are published\nINFO = 1 Just necessary logs are published\n</code></pre> <p>These values can be used in the publish dir directive to enable or disable the output of logs.</p> <pre><code>   publishDir params.output, mode: \"${params.publishDirMode}\", saveAs: { filename -&gt; getOutput(params.runid, \"pasolli/mash/sketch\", filename) }, \\\n        pattern: \"{**.out,**.err, **.sh, **.log}\", enabled: params.logLevel &lt;= params.LOG_LEVELS.ALL\n</code></pre> <p>Furthermore the <code>params.LOG_LEVELS.*</code> parameters can be used inside of a process to enable or disable intermediate results for debugging purposes. In cases where the log is send to the pDumpLogs process (see Process section), you can specify the log level as part of the tuple:</p> <pre><code>tuple env(FILE_ID), val(\"${output}\"), val(params.LOG_LEVELS.INFO), file(\".command.sh\"), \\\n        file(\".command.out\"), file(\".command.err\"), file(\".command.log\"), emit: logs\n</code></pre>"},{"location":"developer_guidelines/#resources","title":"Resources","text":"<p>Usually all processes get a label that is linked to the flavor provided in the resources section of the configuration file (e.g. <code>small</code>, <code>medium</code>, <code>large</code>). In cases where we can foresee that a processes might need more RAM depending on the size of the input data, it is also possible to use the getMemoryResources and getCPUsResources methods provided by the Utils class:</p> <p>Example:</p> <pre><code>memory { Utils.getMemoryResources(params.resources.small, \"${sample}\", task.attempt, params.resources) }\n\ncpus { Utils.getCPUsResources(params.resources.tiny.small, \"${sample}\", task.attempt, params.resources) }\n</code></pre> <p>One example where it might make sense to use this option is when a process uses <code>csvtk join</code> and uses per default a label with little RAM assigned.</p>"},{"location":"developer_guidelines/#time-limit","title":"Time Limit","text":"<p>Every process must define a time limit which will never be reached on \"normal\" execution. This limit is only useful for errors in the execution environment which could lead to an endless execution of the process.</p> <p>You can use the setTimeLimit helper method to add a user configurable time limit.</p> <p>Example:</p> <pre><code>time Utils.setTimeLimit(params.steps.qc.fastp, params.modules.qc.process.fastp.defaults, params.resources.highmemMedium)\n</code></pre>"},{"location":"developer_guidelines/#databases","title":"Databases","text":"<p>If the same database is downloaded during runtime by multiple processes, it takes up an unnecessary ammount of disc space. One idea is too always use the same place to store these databases. This place should be described in <code>params.databases</code>. If other processes try to use this databases they can look at <code>params.databases</code> on the current machine.  If it is present it can be used, if not it should be downloaded. Through this procedure only one copy of each databases is used, which is space-saving. Links to the actual database should contain the database version number or the date of download.</p>"},{"location":"developer_guidelines/#configuration","title":"Configuration","text":"<p>Every process should be configurable by providing a parameters string to the tool in the process. Every module should use the following specification in the configuration file:</p> <pre><code>steps:\n  moduleName:\n    parameter: 42\n    processName:\n      additionalParams: \" --super-flag \"\n      timeLimit: \"AUTO\"\n</code></pre> <p>Please check the process chapter regarding possible values for the time limit attribute. Additional params can have a string value (like the example above) that is provided to the tool:</p> <pre><code>pProcess {\n\n   ...\n\n  shell:\n  \"\"\"\n  supertool !{params.steps.moduleName.processName.parameter}  !{params.steps.moduleName.processName.additionalParams}\n  \"\"\"\n}\n</code></pre> <p>The value of the <code>additionalParams</code> key can also be a map if multiple tools are used in the same process:</p> <pre><code>steps:\n  moduleName:\n    parameter: 42\n    processName:\n      additionalParams:\n         toolNameA: \" -c 84  \"\n         toolNameB: \" --super-flag \"\n</code></pre> <p><code>parameter</code> fields can hold hardcoded parameters that hold a defined value like a number that should not be a string. One use case of those parameters is that they can be reused for multiple tools.</p> <p>Example:</p> <pre><code>pProcess {\n\n   ...\n\n  shell:\n  \"\"\"\n  toolNameA --super-specific-number-flag !{params.steps.moduleName.parameter}\n  toolNameB --similar-flag-to-toolA !{params.steps.moduleName.parameter} \n  \"\"\"\n}\n</code></pre>"},{"location":"developer_guidelines/#internal-configuration","title":"Internal Configuration","text":"<p>The <code>_wConfigurePipeline</code> workflow in the main.nf file should be used for setting  pipeline parameters that are need for fullfilling the user provided configuration.</p> <p>Example: Lets assume the user enables the plasmid module. In that case it is mandatory that  the assembler produces a fastg file independend of the user provided settings of the assembler. In that case the fastg parameter of any assembler will be set to <code>true</code> by the <code>_wConfigurePipeline</code> method.</p>"},{"location":"developer_guidelines/#toolkit-docker-images","title":"Toolkit Docker Images","text":"<p>Dockerfiles of Docker images that are build by toolkit developers can be found in the <code>docker</code> directory. The name of the directory (i.e.: <code>toolkit-python-env</code> in <code>docker/toolkit-python-env</code>) is used for the docker image name. All images belong to the metagenomics quay.io organisation which is owned by the Computational Metagenomics group in Bielefeld. A docker repository in the <code>metagenomics</code> orginsation must be created by the organisation owner, before the actual image can be build. The version of the image specified in the <code>VERSION</code> file (i.e. <code>docker/toolkit-python-env/VERSION</code>) is used for the image tag (<code>metagenomics/toolkit-python-env:VERSION</code>). An image build is only triggered if the version in the VERSION file is updated on the dev or master branch.</p>"},{"location":"developer_guidelines/#wiki","title":"Wiki","text":"<p>For building the documentation we are using mkdocs in combination with mkdocs-material and mike for building versioned wiki pages. Using <code>TOOLKIT_TAG=0.5.0 make wiki_publish</code> the local wiki pages are uploaded to Github pages. Please use semantic versioning for specifying the version number.</p> <p>You can work on these html files locally by running <code>make dev_wiki</code>. But please note that by build the static html file for upload, the navigation might change. You can view the final html file by building the html file (see Makefile <code>make help</code>). </p>"},{"location":"developer_guidelines/#utils","title":"Utils","text":"<p>We do not want to duplicate code and thats why we should store methods in the lib/Utils.groovy file. The Utils class can be used in any module. </p>"},{"location":"developer_guidelines/#database-download","title":"Database Download","text":"<p>This section explains how a developer is able to implement the database download strategy as explained in the user documentation.  Example implementations can be found in the gtdb, checkm or rgi scripts.</p> <p>The first step is to check if the user provides an already extracted database: </p> <pre><code>DB_PATH=\"\"\nif [ -z \"!{EXTRACTED_DB}\" ]\nthen\n   # Fetch user parameter for not extracted db path and run flock (see next section)\n   DB_PATH=\"not extracted\"\nelse\n  # Set variable to extracted db path\nfi\n</code></pre> <p>Since the download is not directly handled by nextflow and paths to the files need to be downloaded, any file or directory must be mounted first to the container. For this reason you have to add the <code>setDockerMount</code> function with the database config as input to  the <code>containerOptions</code> parameter:</p> <pre><code>containerOptions \" other container options \" + setDockerMount(params.steps?.magAttributes?.checkm?.database)\n</code></pre>"},{"location":"developer_guidelines/#filesystem-locks","title":"Filesystem locks","text":"<p>Multiple jobs of the same process (e.g. GTDB) are able to synchronize the download of a database by using filesystem locks. The download is handled by the <code>concurrentDownload.sh</code> script and should be executed the following way:</p> <pre><code>flock LOCK_FILE concurrentDownload.sh --output=DATABASE \\\n           --httpsCommand=COMMAND \\\n           --localCommand=COMMAND \\\n           --s3FileCommand=COMMAND \\\n           --s3DirectoryCommand=COMMAND \\\n           --s5cmdAdditionalParams=S5CMD_PARAMS \\\n           --link=LINK \\\n           --expectedMD5SUM=USER_VERIFIED_DATABASE_MD5SUM\n</code></pre> <p>where   * <code>LOCK_FILE</code> is a file that is used for locking. Processes will check if the file is currently locked before trying to download anything.     This file should ideally placed in the <code>params.database</code> directory of the specific tool (e.g. !{params.databases}/rgi).</p> <ul> <li> <p><code>DATABASE</code> is the directory that is used for placing the specific database.</p> </li> <li> <p><code>COMMAND</code> is the command used to download and extract the database and to remove it afterwards.      (e.g. \"wget -O data.tar.gz $DOWNLOAD_LINK &amp;&amp; tar -xvf data.tar.gz ./card.json &amp;&amp; rm data.tar.gz\" for the <code>--httpsCommand</code> flag)</p> </li> <li> <p><code>USER_VERIFIED_DATABASE_MD5SUM</code> is the MD5SUM of the extracted database that the user should test manually before executing the pipeline.</p> </li> <li> <p><code>S5CMD_PARAMS</code> allows you to set s5cmd specific parameters. For more information check the s5cmd documentation. </p> </li> <li> <p><code>LINK</code> is the link that will be used to test if the file is accessible by S3, HTTPS or is available via a local path.</p> </li> <li> <p><code>USER_VERIFIED_DATABASE_MD5SUM</code> Before a database is downloaded, the script checks the MD5SUM of an already downloaded database against a user specified one.      If it does not equal, the script will download the database again.</p> </li> </ul>"},{"location":"developer_guidelines/#tests","title":"Tests","text":"<p>You can test your tool against different database inputs by using the <code>make runDatabaseTest</code> command. You will have to specify multiple databases  that are accessible via https, S3, local path etc. Please check github actions file for how to run these tests.</p>"},{"location":"developer_guidelines/#polished-variables","title":"Polished Variables","text":"<p>Sometimes user input variables must be polished before they can used in our code. Thats why the nextflow config adds a namespace to the params namespace called <code>polished</code>. For example the params.databases variable must end with a slash in order to be used as part of a docker mount. Thats why there is a variable <code>params.polished.databases</code> that should be used instead.  </p>"},{"location":"developer_guidelines/#other","title":"Other","text":"<ol> <li> <p>Magic numbers should not be used.</p> </li> <li> <p>Variable, method, workflow, folder and process names should be written in camelcase.</p> </li> </ol>"},{"location":"full_pipeline/","title":"Full Pipeline","text":"<p>The full pipeline mode allows you to run the per-sample part and the aggregation part in one execution (see schematic overview). In contrast to the Quickstart section, this chapter refers to the execution of the Toolkit on a cluster system. In this section, you will run the Toolkit with a dataset stored on a remote server and then learn how to replace it with your own local data.  You will then learn how to add additional analyses steps to your pipeline configuration and how to replace the tools in a module with alternative ones.</p>"},{"location":"full_pipeline/#requirements","title":"Requirements","text":"<ol> <li>SLURM: The Toolkit was mainly developed for cloud-based clusters using SLURM as a resource orchestrator.</li> <li>Docker: Install Docker by following the official Docker installation instructions.</li> <li>Java: In order to run Nextflow, you need to install Java on your machine, which can be achieved via <code>sudo apt install default-jre</code>.</li> <li>Nextflow should be installed. Please check the official Nextflow instructions</li> <li>You will need at least 150 GB of scratch space on every worker node. </li> </ol>"},{"location":"full_pipeline/#part-1-run-the-toolkit-with-a-basic-config","title":"Part 1: Run the Toolkit with a basic config","text":"<p>In this section you will learn how to run the Toolkit. The input data will be downloaded automatically. The following Toolkit analyses will be performed: quality control, assembly, binning, taxonomic classification, contamination and completeness of MAGs, and gene prediction and annotation via Prokka.</p> <p>Default Configuration</p> <p>Please note that in the following you will modify our default (best practice) configuration. For most cases you don't need to modify our default configuration, you might only need to remove or add analyses.</p> <pre><code>NXF_HOME=$PWD/.nextflow NXF_VER=23.10.0 nextflow run metagenomics/metagenomics-tk -work-dir $(pwd)/work \\\n    -profile slurm \\\n    -entry wFullPipeline \\\n    -ansi-log false \\\n    -params-file  https://raw.githubusercontent.com/metagenomics/metagenomics-tk/refs/heads/master/default/fullPipeline_illumina_nanpore_getting_started_part1.yml \\\n    --logDir log1 \\\n    --s3SignIn false \\\n    --scratch /vol/scratch \\\n    --databases /vol/scratch/databases \\\n    --output output \\\n    --input.paired.path https://raw.githubusercontent.com/metagenomics/metagenomics-tk/refs/heads/master/test_data/fullPipeline/reads_split.tsv\n</code></pre> <p>where</p> <ul> <li><code>NXF_HOME</code> points to the directory where Nextflow internal files and additional configs are stored. The default location is your home directory.  However, it might be that your home directory is not shared among all worker nodes and is only available on the master node.  In this example  the variable points to your current working directory (<code>$PWD/.nextflow</code>).</li> <li><code>-work-dir</code> points in this example to your current working directory and should point to a directory that is shared between all worker nodes.</li> <li><code>-profile</code> defines the execution profile that should be used (local or cluster computing).</li> <li><code>-entry</code> is the entrypoint of the Toolkit.</li> <li><code>-params-file</code> sets the parameters file which defines the parameters for all tools. (see input section below)</li> <li><code>--logDir</code> points to a directory where your trace TSV, a timeline HTML of the executed processes and a report regarding the resource consumption of the workflow is saved.</li> <li><code>--s3SignIn</code> defines if any S3 login for retrieving inputs is necessary. See the S3 configuration section for more information on how to configure the Toolkit for possible S3 input data.</li> <li><code>--scratch</code> is the directory on the worker node where all intermediate results are saved.</li> <li><code>--databases</code> is the directory on the worker node where all databases are saved. Already downloaded and extracted databases on a shared file system can be configured in the database setting of the corresponding database section in the configuration file.</li> <li><code>--output</code> is the output directory where all results are saved. If you want to know more about which outputs are created, then please refer to the modules section.</li> <li><code>--input.paired.path</code> is the path to a TSV file that lists the datasets that should be processed. Besides paired-end data there are also other input types. Please check the input section.</li> </ul> <p>Parameter override</p> <p>Any parameters defined with a double dash are parameters that override parameters that are already specified in the YAML file.</p>"},{"location":"full_pipeline/#input","title":"Input","text":"<p>Here you can see the actual input TSV and YAML which was used by the previous command and automatically downloaded by Nextflow.  The TSV file only describes the input data, while the YAML file represents the Toolkit configuration.</p> TSV TableConfiguration File <pre><code>SAMPLE  READS1  READS2\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read2_1.fq.gz\ntest2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read2_1.fq.gz\n</code></pre> <p>Must include the columns <code>SAMPLE</code>, <code>READS1</code> and <code>READS2</code>. <code>SAMPLE</code> must contain unique dataset identifiers without whitespaces or special characters. <code>READS1</code> and <code>READS2</code> are paired reads and can be HTTPS URLs, S3 links or files.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\ninput:\n  paired:\n    path: \"test_data/fullPipeline/reads_split.tsv\"\n    watch: false\noutput: output\nlogDir: log\nrunid: 1\ndatabases: \"/vol/scratch/databases\"\npublishDirMode: \"symlink\"\nlogLevel: 1\nscratch: \"/vol/scratch\"\nsteps:\n  qc:\n    fastp:\n       # For PE data, the adapter sequence auto-detection is disabled by default since the adapters can be trimmed by overlap analysis. However, you can specify --detect_adapter_for_pe to enable it.\n       # For PE data, fastp will run a little slower if you specify the sequence adapters or enable adapter auto-detection, but usually result in a slightly cleaner output, since the overlap analysis may fail due to sequencing errors or adapter dimers.\n       # -q, --qualified_quality_phred       the quality value that a base is qualified. Default 15 means phred quality &gt;=Q15 is qualified.\n       # --cut_front move a sliding window from front (5') to tail, drop the bases in the window if its mean quality is below cut_mean_quality, stop otherwise.\n       # --length_required  reads shorter than length_required will be discarded, default is 15. (int [=15])\n       # PE data, the front/tail trimming settings are given with -f, --trim_front1 and -t, --trim_tail1\n       additionalParams: \" --detect_adapter_for_pe -q 20 --cut_front --trim_front1 3 --cut_tail --trim_tail1 3 --cut_mean_quality 10 --length_required 50 \"\n       timeLimit: \"AUTO\"\n    nonpareil:\n      additionalParams: \" -v 10 -r 1234 \"\n    kmc:\n      timeLimit: \"AUTO\"\n      additionalParams:\n        # Computes k-mer distribution based on k-mer length 13 and 21\n        #  -sm - use strict memory mode (memory limit from -m&lt;n&gt; switch will not be exceeded)\n        #  -cs&lt;value&gt; - maximal value of a counter\n        count: \" -sm -cs10000 \"\n        histo: \" -cx50000 \"\n\n  qcONT:\n    porechop:\n       additionalParams:\n         # Input files are split into chunks because of RAM issues\n         chunkSize: 450000\n         porechop: \"\"\n        # --keep_percent Throw out the worst 10% of reads. This is measured by bp, not by read count. So this option throws out the worst 10% of read bases. \n        # \n         filtlong: \" --min_length 1000  --keep_percent 90 \"\n    nanoplot:\n      additionalParams: \"\"\n  assembly:\n    megahit:\n      # --mem-flag 0 to use minimum memory, --mem-flag 1 (default) moderate memory and --mem-flag 2 all memory.\n      # meta-sensitive: '--min-count 1 --k-list 21,29,39,49,...,129,141' \n      # meta-large:  '--k-min  27  --k-max 127 --k-step 10' (large &amp; complex metagenomes, like soil)\n      additionalParams: \" --min-contig-len 1000 --presets meta-sensitive \"\n      fastg: true\n      resources:\n        RAM:\n          mode: 'PREDICT'\n          predictMinLabel: 'medium'\n  assemblyONT:\n    metaflye:\n      additionalParams: \" -i 1 \"\n      quality: \"AUTO\"\n  binning:\n    bwa2:\n      additionalParams: \n        bwa2: \" \"\n        # samtools flags are used to filter resulting bam file\n        samtoolsView: \" -F 3584 \" \n    contigsCoverage:\n      additionalParams: \" --min-covered-fraction 0 --min-read-percent-identity 100 --min-read-aligned-percent 100 \"\n    genomeCoverage:\n      additionalParams: \" --min-covered-fraction 0 --min-read-percent-identity 100 --min-read-aligned-percent 100 \"\n    # Primary binning tool\n    metabat:\n      # Set --seed positive numbers to reproduce the result exactly. Otherwise, random seed will be set each time.\n      additionalParams: \" --seed 234234  \"\n    # Secondary binning tool for use with MAGscot\n  binningONT:\n    minimap:\n      additionalParams: \n        minimap: \" \"\n        # samtools flags are used to filter resulting bam file\n        samtoolsView: \" -F 3584 \" \n    contigsCoverage:\n      additionalParams: \" --min-covered-fraction 0  --min-read-aligned-percent 100 \"\n    genomeCoverage:\n      additionalParams: \" --min-covered-fraction 0  --min-read-aligned-percent 100 \"\n    metabat:\n      additionalParams: \" --seed 234234  \"\n  magAttributes:\n    # gtdbtk classify_wf\n    # --min_af minimum alignment fraction to assign genome to a species cluster (0.5)\n    gtdb:\n      buffer: 1000\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/gtdbtk_r214_data.tar.gz\n          md5sum: 390e16b3f7b0c4463eb7a3b2149261d9\n      additionalParams: \" --min_af 0.65 --scratch_dir . \"\n    checkm2:\n      database:\n        download:\n          source: \"https://openstack.cebitec.uni-bielefeld.de:8080/databases/checkm2_v2.tar.gz\"\n          md5sum: a634cb3d31a1f56f2912b74005f25f09\n      additionalParams: \"  \"\n  annotation:\n    prokka:\n      defaultKingdom: false\n      additionalParams: \" --mincontiglen 500 \"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre>"},{"location":"full_pipeline/#output","title":"Output","text":"<p>You can read more about the produced output on the respective modules page.</p>"},{"location":"full_pipeline/#part-2-run-the-toolkit-with-your-own-data","title":"Part 2: Run the Toolkit with your own data","text":"<p>Now that you have been able to run the Toolkit on your system, let's use the same configuration, but with your own data that may already be  locally available . We will simulate the provisioning of local files by first downloading sample paired-end FASTQ files (size: 1.2 GB).  Please note that these are the same fastq files as in the previous part. The only difference to previous part is that you will download the data beforehand. </p> <pre><code>mkdir inputFiles\nwget -P inputFiles https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz \nwget -P inputFiles https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read2_1.fq.gz \n</code></pre> <p>In addition, you have to tell the Toolkit the name of the sample and the path to the files that are the subject of the analysis. For this reason, we will create a file that contains three columns: sample, path to left reads, and path to right reads.</p> <pre><code>INPUT_FILES=$(pwd)/inputFiles/input.tsv\necho -e \"SAMPLE\\tREADS1\\tREADS2\" &gt; $INPUT_FILES\necho -e \"MYDATA\\t$(readlink -f inputFiles/read1*)\\t$(readlink -f inputFiles/read2*)\" &gt;&gt; $INPUT_FILES\n</code></pre> <p>Now that the files are created, you are ready to execute the Toolkit on your data but with a modified command of the first part. The only difference is that you modify the <code>--input.paired.path</code> variable.</p> <pre><code>NXF_HOME=$PWD/.nextflow NXF_VER=23.10.0 nextflow run metagenomics/metagenomics-tk -work-dir $(pwd)/work \\\n    -profile slurm \\\n    -entry wFullPipeline \\\n    -ansi-log false \\\n    -params-file  https://raw.githubusercontent.com/metagenomics/metagenomics-tk/refs/heads/master/default/fullPipeline_illumina_nanpore_getting_started_part1.yml \\\n    --logDir log2 \\\n    --s3SignIn false \\\n    --scratch /vol/scratch \\\n    --databases /vol/scratch/databases \\\n    --output my_data_output \\\n    --input.paired.path inputFiles/input.tsv\n</code></pre> <p>Now you can go through the <code>my_data_output</code> folder and check the results. The next section describes how to modify the analysis that was performed.</p>"},{"location":"full_pipeline/#part-3-exchange-tools-of-a-module","title":"Part 3: Exchange tools of a module","text":"<p>In some cases, you may also be interested in replacing a tool from one module with another. For example, you might be interested in comparing the assembler that is set as default with another one like MetaSpades.</p> <p>In this case you could replace the MEGAHIT part with the MetaSpades config.</p> <pre><code>NXF_HOME=$PWD/.nextflow NXF_VER=23.10.0 nextflow run metagenomics/metagenomics-tk -work-dir $(pwd)/work \\\n    -profile slurm \\\n    -ansi-log false \\\n    -entry wFullPipeline \\\n    -params-file  https://raw.githubusercontent.com/metagenomics/metagenomics-tk/refs/heads/master/default/fullPipeline_illumina_nanpore_getting_started_part3.yml \\\n    --logDir log3 \\\n    --s3SignIn false \\\n    --scratch /vol/scratch \\\n    --databases /vol/scratch/databases \\\n    --output my_data_spades_output \\\n    --input.paired.path inputFiles/input.tsv\n</code></pre> <p>This is the MetaSpades part that was used by the previous command instead of the MEGAHIT configuration:</p> <pre><code>  assembly:\n    metaspades:\n      additionalParams: \"  \"\n      fastg: true\n</code></pre> <p>If you now compare the contigs of the two assemblers with the following command,  you will notice that the MetaSpades assembly has a higher N50 than the MEGAHIT one. </p> <pre><code>cat my_data_spades_output/MYDATA/1/assembly/*/metaspades/MYDATA_contigs_stats.tsv\n#SAMPLE  file                    format  type    num_seqs  sum_len    min_len avg_len max_len Q1      Q2      Q3      sum_gap N50     Q20(%)  Q30(%)  GC(%)\n#MYDATA  MYDATA_contigs.fa.gz    FASTA   DNA     1761      4521427    1000    2567.5  26470   1149.0  1408.0  2119.0  0       3799    0.00    0.00    55.07\n\ncat my_data_output/MYDATA/1/assembly/*/megahit/MYDATA_contigs_stats.tsv\n#SAMPLE  file                    format  type    num_seqs  sum_len    min_len avg_len max_len Q1      Q2      Q3      sum_gap N50     Q20(%)  Q30(%)  GC(%)\n#MYDATA  MYDATA_contigs.fa.gz    FASTA   DNA     95227     60110517   56      631.2   346664  234.0   286.0   439.0   0       1229    0.00    0.00    57.34\n</code></pre>"},{"location":"full_pipeline/#part-4-add-further-analyses","title":"Part 4: Add further analyses","text":"<p>Now, suppose you also want to check the presence of your genes in other databases. With the help of the Toolkit, you could create your own database with the syntax as described  in the wiki. In this example, we will use the bacmet database. What you need to do here is to add the following part to the annotation section of the Toolkit configuration.</p> <p>The bacmet database snippet is the following:</p> <pre><code>    mmseqs2:\n      chunkSize: 20000\n      bacmet20_experimental:\n        additionalParams:\n          search : ' --max-seqs 300 --max-accept 50 -c 0.8 --cov-mode 0 --start-sens 4 --sens-steps 1 -s 6 --num-iterations 2 -e 0.001 --e-profile 0.01 --db-load-mode 3 '\n          additionalColumns: \"\"\n        database:\n          download:\n            source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/bacmet20_experimental.tar.zst\n            md5sum: 57a6d328486f0acd63f7e984f739e8fe\n</code></pre> <p>By re-running the Toolkit with this configuration, you will see that the previous results were cached (see next snippet) and only the annotation part is re-executed.</p> <pre><code>...\n[a7/d8e782] Cached process &gt; wFullPipeline:_wProcessIllumina:wShortReadBinningList:_wBinning:pMetabat (MYDATA)\n[c3/537cbc] Cached process &gt; wFullPipeline:_wProcessIllumina:wShortReadBinningList:_wBinning:pCovermContigsCoverage (Sample: MYDATA)\n[bb/fcd1aa] Cached process &gt; wFullPipeline:_wProcessIllumina:wShortReadBinningList:_wBinning:pCovermGenomeCoverage (Sample: MYDATA)\n[8c/08e157] Cached process &gt; wFullPipeline:wMagAttributesList:_wMagAttributes:pGtdbtk (Sample: MYDATA)\n[4b/286c49] Cached process &gt; wFullPipeline:wMagAttributesList:_wMagAttributes:pCheckM2 (Sample: MYDATA)\n...\n</code></pre>"},{"location":"full_pipeline/#further-reading","title":"Further Reading","text":"<ul> <li> <p>Continue to the aggregation part of the Getting Started tutorial to learn how to aggregate data of multiple samples.</p> </li> <li> <p>You can check in our configuration section for how to further adapt the Toolkit to your infrastructure.</p> </li> <li> <p>In case you want to import the output to EMGB, please visit the EMGB section.</p> </li> <li> <p>If you want to add your own sequence databases, you can read here how to do this.</p> </li> <li> <p>You might want to adjust the resource requirements of the Toolkit to your infrastructure.</p> </li> </ul>"},{"location":"module_specification/","title":"Module Specification","text":""},{"location":"module_specification/#assembly","title":"Assembly","text":"<ul> <li>Version: 0.2.0</li> </ul>"},{"location":"module_specification/#output","title":"Output:","text":"<p>Assembly file names must fulfill the following name pattern:</p> <pre><code>SAMPLENAME_contigs.fa.gz\n</code></pre> <p>Contig names must be renamed according to the following pattern:</p> <p><code>SAMPLEID_SEQUENCECOUNTER_SEQUENCEHASH</code></p> <p>where</p> <ul> <li> <p><code>SAMPLEID</code> is the name of the dataset (e.g: <code>SRR234235</code>)</p> </li> <li> <p><code>SEQUENCECOUNTER</code> is the counter of the contig entry in the fasta file (e.g: 2)</p> </li> <li> <p><code>SEQUENCEHASH</code> are the last 5 characters of an md5sum hash of the fasta entry without the header and newline character.       (eg. echo -n \"ACGT\" | md5sum | cut -d ' ' -f 1 | cut -c -5 )</p> </li> </ul>"},{"location":"module_specification/#binning","title":"Binning","text":"<ul> <li>Version: 0.5.0</li> </ul>"},{"location":"module_specification/#output_1","title":"Output:","text":"<p>Binning file names must fulfill the following name pattern:</p> <pre><code>SAMPLENAME_bin.NUMBER.fa\n</code></pre> <p>Where <code>NUMBER</code> is a unique identifier per SAMPLE.</p> <p>Contig names must be renamed according to the following pattern:</p> <p><code>SAMPLEID_SEQUENCECOUNTER_SEQUENCEHASH MAG=BINNUMBER</code></p> <p>where</p> <ul> <li> <p><code>SAMPLEID</code>, <code>SEQUENCECOUNTER</code> and <code>SEQUENCEHASH</code>  definitions can be inspected in the assembly specification.</p> </li> <li> <p><code>BINNUMBER</code> is an unique identifier per SAMPLE.</p> </li> </ul>"},{"location":"module_specification/#mag-attributes","title":"MAG Attributes","text":"<ul> <li>Version: 0.1.0</li> </ul>"},{"location":"module_specification/#output_2","title":"Output:","text":"<pre><code>SAMPLENAME_TOOLNAME_CHUNK.tsv\n</code></pre> <p>where  * <code>TOOLNAME</code> could be for example <code>checkm</code>, <code>gtdb</code> etc.  * <code>CHUNK</code> is a random identifier that produces values for one part of all MAGs of a given sample.</p>"},{"location":"module_specification/#format","title":"FORMAT","text":"<p>The header line specifies the following columns: </p> <pre><code>BIN_ID  SAMPLE  BIN_ATTRIBUTE1  BIN_ATTRIBUTE2 ...\n</code></pre> <p>where    * <code>BIN_ID</code> is unique for the samples.   * <code>BIN_ATTRIBUTES</code> All column names that are not <code>BIN_ID</code> or <code>SAMPLE</code> can be any property of a MAG, like contamination, completeness etc.</p>"},{"location":"module_specification/#quality-control","title":"Quality Control","text":"<ul> <li>Version: 0.1.0</li> </ul>"},{"location":"module_specification/#output_3","title":"Output:","text":"<pre><code>SAMPLE_interleaved.qc.fq.gz\n</code></pre>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#contents","title":"Contents","text":"<p>The Getting Started tutorial explains the first steps in running the Toolkit on a cloud-based cluster system. It consists of two main parts. </p> <ol> <li>In the first part you will learn how to run and configure the Toolkit.</li> <li>The second part tells you how to aggregate multiple samples of a Toolkit output.</li> </ol> <p>Other parameters can be found in the configuration section.</p>"},{"location":"overview/#full-pipeline-vs-separate-modules","title":"Full Pipeline vs. Separate Modules","text":"<p>The Metagenomics-Toolkit allows you to run either the full pipeline of assembly, binning and many other downstream analysis tasks or the individual modules. The Toolkit can be configured by providing the module configuration via a YAML file and a flag for the corresponding module or full pipeline mode. Options for the global pipeline configuration can be viewed here.</p> <p>The Full Pipeline mode consists mainly of two parts. One part (per-sample) of the Toolkit processes each dataset individually  by applying analyses such as quality control, assembly, binning and annotation. The second part aggregates and combines the results of the individual datasets by applying modules such as dereplication and co-occurrence analysis. You can either run the first and second part consecutively or separately where the second part can be applied on the output of the first  part.</p> <p>Sensitive data</p> <p>Please do never place sensitive information in any of the YAML configuration files since the configuration is part of the pipeline output.</p>"},{"location":"overview/#error-strategy","title":"Error Strategy","text":"<p>All tools follow the same error strategy. The execution of a tool is retried three times. If the run fails the fourth time, it will be ignored. If the execution is ignored, the Toolkit will continue to run all tools that do not depend on the output of the failed tool run. Exceptions of this handling are specified in the corresponding module section.</p>"},{"location":"pipeline_input/","title":"Pipeline Input Configuration","text":""},{"location":"pipeline_input/#configuration-of-input-parameters-of-the-full-pipeline-mode","title":"Configuration of input parameters of the full pipeline mode","text":""},{"location":"pipeline_input/#paired-end-input","title":"Paired End Input","text":"<p>The input should be a path to a tsv file containing a sample id, as well as a path to the left and right read.</p> <p>Example: <pre><code>input:\n  paired:\n    path: \"test_data/fullPipeline/reads_split.tsv\"\n</code></pre></p>"},{"location":"pipeline_input/#nanopore-input","title":"Nanopore Input","text":"<p>For Nanopore data a seperate input file should be specified.</p> <pre><code>input:\n  ont:\n    path: \"test_data/fullPipeline/ont.tsv\"\n</code></pre>"},{"location":"pipeline_input/#generic-sra","title":"Generic SRA","text":"<p>The toolkit is able to fetch fastq files based on SRA run accession ids from the NCBI or from a mirror based on S3:</p> <pre><code>input:\n  SRA:\n    pattern:\n      ont: \".+[^(_1|_2)].+$\"\n      illumina: \".+(_1|_2).+$\"\n    S3:\n      path: test_data/SRA/samples.tsv \n      bucket: \"s3://ftp.era.ebi.ac.uk\" \n      prefix: \"/vol1/fastq/\"\n      watch: false\n      patternONT: \".+[^(_1|_2)].+$\"\n      patternIllumina: \".+(_1|_2).+$\"\n</code></pre> <p>where:   * <code>path</code> is the path to a file containing a column with <code>ACCESSION</code> as header. The <code>ACCESSION</code> column contains either SRA run or study accessions.</p> <ul> <li> <p><code>bucket</code> is the S3 Bucket hosting the data.</p> </li> <li> <p><code>prefix</code> is the path to the actual SRA datasets.</p> </li> <li> <p><code>watch</code> if true, the file specified with the <code>path</code> attribute is watched and every time a new SRA run id is      appended, the pipeline is triggered. The pipeline will never finish in this mode. Please note that watch currently only works      if only one input type is specified (e.g \"ont\" or \"paired\" ...)</p> </li> <li> <p><code>patternONT</code> and <code>patternIllumina</code> are patterns that are applied on the specified mirror in order to select the correct input files.</p> </li> </ul>"},{"location":"pipeline_input/#ncbi-sra","title":"NCBI SRA","text":"<p>With the following mode SRA datasets can directly be fetched from SRA.</p> <pre><code>input:\n  SRA:\n    pattern:\n      ont: \".+[^(_1|_2)].+$\"\n      illumina: \".+(_1|_2).+$\"\n    NCBI:\n      path: test_data/SRA/samples.tsv\n</code></pre>"},{"location":"pipeline_specification/","title":"Pipeline Specification","text":""},{"location":"pipeline_specification/#output-and-best-practice","title":"Output and best practice","text":""},{"location":"pipeline_specification/#motivation","title":"Motivation","text":"<ul> <li> <p>The output section is a collection of <code>best practices</code> for storing results of the <code>meta-omics-toolkit</code> output. The definitions are motivated by the fact that the pipeline will be continuously updated and results of different pipeline versions and modes must be differentiated.</p> </li> <li> <p>The idea is to run the pipeline on results of previous runs.</p> </li> </ul>"},{"location":"pipeline_specification/#rules-for-dataset-output","title":"Rules for dataset output","text":"<p>Outputs are produced by using the <code>publish dir</code> directive.</p> <p><pre><code>DATASET_ID/RUN_ID/MODULE/VERSION/TOOL/\n</code></pre> where    * <code>DATASET_ID</code> specifies the ID of a dataset such as the SRA run ID.    * <code>RUN_ID</code> specifies one possible run of the full or partial pipeline. The <code>RUN_ID</code> identifier can be any user provided identifier to keep track of multiple pipeline runs.    * <code>MODULE</code> specifies the name of the pipeline module (e.g. binning).    * <code>VERSION</code> specifies the module version number which follows semantic versioning (1.2.0).    * <code>TOOL</code> specifies the name of the tool that is executed as part of the module (e.g <code>megahit</code> of the assembly module).</p> <p>It is suggested that a RUN_ID output should never contain multiple versions of the same module. E.g.:  <code>DATASET_ID/1/Binning/1.2.0/metabat</code> and <code>DATASET_ID/1/Binning/1.3.0/metabat</code>.</p> <p>If a partial pipeline run (B) uses outputs of a previous run (A) (e.g. a binning tool uses the output of an assembler) and the previous run (A) alreads contains the output of an older version of run (B), then a new RUN_ID folder must be created.</p> <p>If a partial pipeline run (B) uses outputs of a previous run (A) (e.g. a binning tool uses the output of an assembler) and the previous run (A) does not contain the output of an older version of run (B), then the existing RUN_ID folder must be reused.</p>"},{"location":"pipeline_specification/#run-versioning","title":"Run Versioning","text":"<p>Every dataset must contain a <code>TOOL</code> folder called <code>config</code>. The <code>config</code> folder contains descriptions of the parameters and the version used for the specific pipeline run.</p>"},{"location":"pipeline_specification/#examples","title":"Examples","text":""},{"location":"pipeline_specification/#example-1","title":"Example 1:","text":"<p>We assume that the following folder already exists:</p> <pre><code>/SRA1/1/ASSEMBLY/1.2/MEGAHIT\n</code></pre> <p>If the MODULE output does not contain a BINNING output then the existing RUN folder must be reused:</p> <pre><code>/SRA1/1/ASSEMBLY/1.2/MEGAHIT\n/SRA1/1/BINNING/0.3/METABAT\n</code></pre>"},{"location":"pipeline_specification/#example-2","title":"Example 2:","text":"<p>We assume that the following folders already exists:</p> <pre><code>/SRA1/1/ASSEMBLY/1.2/MEGAHIT\n/SRA1/1/BINNING/0.3/METABAT\n</code></pre> <p>If the MODULE output does contain a BINNING output then a new RUN folder must be created:</p> <pre><code>/SRA1/1/ASSEMBLY/1.2/MEGAHIT\n/SRA1/1/BINNING/0.3/METABAT\n/SRA1/2/BINNING/0.4/METABAT\n</code></pre>"},{"location":"pipeline_specification/#rules-for-aggregated-output","title":"Rules for aggregated output","text":"<p>Aggregates outputs in the same way as dataset outputs are produced, by using the publish dir directive with the only difference that no sample identifier are used and the path starts with <code>AGGREGATED</code>.</p> <p>Example:</p> <pre><code>AGGREGATED/RUN_ID/MODULE/VERSION/TOOL/\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":"<p>This quickstart allows you to run a subset of the available tools implemented by the Toolkit on a machine to process two datasets. This tutorial has mainly been tested on a machine with 29 GB of RAM and 14 cores running an Ubuntu operating system.  You will need at least 250 GB of disk space. The disk were your docker images and containers are created has to be at least 17 GB.</p>"},{"location":"quickstart/#requirements","title":"Requirements","text":"<ol> <li>Docker: Install Docker by following the official Docker installation instructions.</li> <li>Java: In order to run Nextflow, you need to install Java on your machine, which can be achieved via <code>sudo apt install default-jre</code>.</li> <li>Nextflow should be installed. Please check the official Nextflow instructions</li> </ol>"},{"location":"quickstart/#run-the-toolkit","title":"Run the Toolkit","text":"<p>The following command will start a subset of all available modules offered by the Toolkit.  All databases will be downloaded to the database directory in your current working directory.</p> <pre><code>NXF_VER=23.10.0 nextflow run metagenomics/metagenomics-tk \\\n      -profile standard \\\n      -entry wFullPipeline \\\n      -params-file default/quickstart.yml \\\n      --logDir logs \\\n      --s3SignIn false \\\n      --scratch false \\\n      --output output \\\n      --databases $(pwd)/databases\n</code></pre> <p>You can read more about the outputs, which are placed in a directory named <code>output</code>, in the corresponding Modules sections.</p>"},{"location":"quickstart/#further-reading","title":"Further Reading","text":"<ul> <li> <p>If you want to configure, add or remove modules, please check the configuration section and  check the Getting Started section for an example.</p> </li> <li> <p>If you want to use your own datasets, then you can read the input configuration sections.  You can check the Getting Started section for an example.</p> </li> <li> <p>In case you want to directly scale out your workflow on a cluster, you should continue with the Getting Started section.</p> </li> </ul>"},{"location":"modules/annotation/","title":"Annotation","text":"<p>The annotation module is able to predict genes and annotate those based on Prokka and a set of user provided databases. A user can add additional formatted databases as part of the configuration by adding a key (Example: <code>kegg</code> ) with  a possible download strategy. See database section for possible download strategies. In addition, the resistance gene identifier is executed by default.</p>"},{"location":"modules/annotation/#input","title":"Input","text":"CommandConfiguration FileTSV Table <pre><code>-entry wAnnotateLocal -params-file example_params/annotation.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the annotation section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>output: \"output\"\nsummary: false\nrunid: 1\ns3SignIn: false\nlogDir: log\ntempdir: \"tmp\"\nscratch: \"/vol/scratch\"\ndatabases: \"/mnt/databases\"\npublishDirMode: \"symlink\"\nsteps:\n   annotation:\n      input: \"test_data/annotation/input_small.tsv\"\n      mmseqs2:\n        chunkSize: 20000\n        kegg:\n          additionalParams:\n            search : ' -s 1 --max-seqs 100 --max-accept 50 --alignment-mode 1 --exact-kmer-matching 1 --db-load-mode 3'\n            additionalColumns: \"\"\n          database:\n            extractedDBPath: '/vol/spool/toolkit/kegg-mirror-2021-01_mmseqs/sequenceDB'\n#        bacmet20_experimental:\n#          params: ' -s 1 --exact-kmer-matching 1 --db-load-mode 3'\n#          database:\n#            download:\n#              source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/bacmet20_experimental.tar.zst\n#              md5sum: 57a6d328486f0acd63f7e984f739e8fe\n        bacmet20_predicted:\n          database:\n            download:\n              source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/bacmet20_predicted.tar.zst\n              md5sum: 55902401a765fc460c09994d839d9b64\n          additionalParams:\n            search : ' -s 1 --max-seqs 100 --max-accept 50 --alignment-mode 1 --exact-kmer-matching 1 --db-load-mode 3'\n            additionalColumns: \"\"\n\n#        vfdb:\n#          params: ' -s 1 --max-seqs 100 --max-accept 50 --alignment-mode 1 --exact-kmer-matching 1 --db-load-mode 3'\n#          database:\n#            download:\n#              source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/vfdb_full_2022_07_29.tar.zst\n#              md5sum: 7e32aaed112d6e056fb8764b637bf49e\n      keggFromMMseqs2:\n         database:\n           extractedDBPath: \"/vol/spool/toolkit/kegg_2021-01/\"\n      rgi: \n        database:\n          download:\n            source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/card_20221209.tar.bz2\n            md5sum: d7e627221a1d4584d1c1795cda774cdb\n        additionalParams: \"\"\n      mmseqs2_taxonomy:\n        runOnMAGs: false\n        gtdb:\n          params: ' --orf-filter-s 1 -e 1e-15'\n          ramMode: false\n          initialMaxSensitivity: 1\n          database:\n            download:\n              source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/gtdb_r214_1_mmseqs.tar.gz\n              md5sum: 3c8f12c5c2dc55841a14dd30a0a4c718\n      prokka:\n        prodigalMode: \"meta\"\n        defaultKingdom: false\n        additionalParams: \" --mincontiglen 200 \"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>DATASET BIN_ID  PATH\ntest3   bin.1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa\ntest1   bin.2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa\ntest1   bin.8   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta\ntest2   bin.9   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta\ntest2   bin.32  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa\n</code></pre>"},{"location":"modules/annotation/#databases","title":"Databases","text":""},{"location":"modules/annotation/#mmseqs2","title":"MMseqs2","text":"<p>MMseqs2 needs a combination of different data, index and dbtype files as \"one\" database, be it in- or output. See MMseqs2 database for more information. As multiple and in most cases, big files are used, tar and zstd are utilized to compress and transport files. Input databases have to be compressed by these and need to end with <code>.tar.zst</code>. Naming inside an archive is irrelevant, as databases are picked automatically. Multiple databases per one archive are not supported, one archive, one database. If the database also includes a taxonomy  as described here, it can also be used for taxonomic classifications with MMseqs2 - Taxonomy. See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_db_ACCESS XXXXXXX\nnextflow secrets set S3_db_SECRET XXXXXXX\n</code></pre> <p>where <code>db</code> is the name of the database that you use in your config file. Example:</p> <pre><code>....\n      vfdb:\n        params: ' -s 1 --max-seqs 100 --max-accept 50 --alignment-mode 1 --exact-kmer-matching 1 --db-load-mode 3'\n        database:\n          download:\n            source: s3://databases/vfdb_full_2022_07_29.tar.zst\n            md5sum: 7e32aaed112d6e056fb8764b637bf49e\n            s5cmd:\n              params: \" --retry-count 30 --endpoint-url https://openstack.cebitec.uni-bielefeld.de:8080 \" \n....\n</code></pre> <p>Based on these settings, you would set the following secret:</p> <pre><code>nextflow secrets set S3_vfdb_ACCESS XXXXXXX\nnextflow secrets set S3_vfdb_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/annotation/#keggfromblast","title":"KEGGFromBlast","text":"<p>KeGGFromBlast is only executed if genes are searched against a KEGG database. There must be a <code>kegg</code> identifier (see example configuration file) in the annotation section. KeGGFromBlast needs a kegg database as input which must be a tar.gz file. See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_kegg_ACCESS XXXXXXX\nnextflow secrets set S3_kegg_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/annotation/#mmseqs-taxonomy","title":"MMSeqs Taxonomy","text":"<p>If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_TAX_db_ACCESS XXXXXXX\nnextflow secrets set S3_TAX_db_SECRET XXXXXXX\n</code></pre> <p>where <code>db</code> is the name of the database that you use in your config file. Example:</p> <pre><code>....\n    mmseqs2_taxonomy:\n      gtdb:\n        params: ' --orf-filter-s 1 -e 1e-15'\n        ramMode: false\n        database:\n          download:\n            source: s3://databases/gtdb_r214_1_mmseqs.tar.gz\n            md5sum: 3c8f12c5c2dc55841a14dd30a0a4c718\n            s5cmd:\n              params: \" --retry-count 30 --endpoint-url https://openstack.cebitec.uni-bielefeld.de:8080 \" \n....\n</code></pre> <p>Based on these settings, you would set the following secrets:</p> <pre><code>nextflow secrets set S3_TAX_gtdb_ACCESS XXXXXXX\nnextflow secrets set S3_TAX_gtdb_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/annotation/#rgi","title":"RGI","text":"<p>RGI needs a CARD database which can be fetched via this link:  https://card.mcmaster.ca/latest/data. The compressed database must be a tar.bz2 file.  See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_rgi_ACCESS XXXXXXX\nnextflow secrets set S3_rgi_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/annotation/#output","title":"Output","text":""},{"location":"modules/annotation/#mmseqs2_1","title":"MMseqs2","text":"<p>Calculated significant matches of a nucleotide/protein query which was compared against a user provided set of databases.</p>"},{"location":"modules/annotation/#mmseqs2-taxonomy","title":"MMseqs2 - Taxonomy","text":"<p>By identifying homologous through searches against a provided MMseqs2 taxonomy-database, MMseqs2 can compute the lowest common ancestor.  This lowest common ancestor is a robust taxonomic label for unknown sequences. These labels are presented in form of an <code>*.taxonomy.tsv</code> file, a <code>*.krakenStyleTaxonomy.out</code> formatted in accordance to the KRAKEN tool outputs and an interactive KRONA plot in form of a html website <code>*.krona.html</code>.</p>"},{"location":"modules/annotation/#prokka","title":"Prokka","text":"<p>Prokka computes <code>*.err</code>, <code>*.faa</code>, <code>*.ffn</code>, <code>*.fna</code>, <code>*.fsa</code>, <code>*.gbk</code>, <code>*.gff</code>, <code>*.sqn</code>, <code>*.tbl</code>, <code>*.tbl</code> for every bin. <code>*.gbk</code> and <code>*.sqn</code> are skipped per default, since tbl2asn runs for quite a while! If you need those files generated by prokka, include: <code>--tbl2asn</code> in the prokka parameters to enable it. Details of all files can be read on the Prokka page. In addition, it also computes a summary tsv file which adheres to the magAttributes specification.</p>"},{"location":"modules/annotation/#keggfromblast_1","title":"KEGGFromBlast","text":"<p>Result <code>*.tsv</code> file filled with KEGG information (like modules, KO's, ...) which could be linked to the input hits.</p>"},{"location":"modules/annotation/#resistance-gene-identifier-rgi","title":"Resistance Gene Identifier (rgi)","text":"<p>The <code>*rgi.tsv</code> files contain the found CARD genes.</p>"},{"location":"modules/assembly/","title":"Assembly","text":""},{"location":"modules/assembly/#input","title":"Input","text":"Command for short read data with optional single end readsCommand for long read dataMegahit Configuration FileMetaspades Configuration FileMetaFlye Configuration FileTSV Table Short ReadTSV Table Nanopore <pre><code>-entry wShortReadAssembly -params-file example_params/assembly.yml\n</code></pre> <pre><code>-entry wOntAssembly -params-file example_params/assemblyONT.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the assembly section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  assembly:\n    input:\n      paired: test_data/assembly/samples.tsv\n      single: test_data/assembly/samplesUnpaired.tsv\n    megahit:\n      additionalParams: \" --min-contig-len 200 \"\n      fastg: true\n      resources:\n         RAM: \n            mode: 'DEFAULT'\n            predictMinLabel: 'AUTO' \n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  assembly:\n    input: \n      paired: test_data/assembly/samples.tsv \n    metaspades:\n      additionalParams: \"  \"\n      fastg: true\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the assemblyONT section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\nsteps:\n  assemblyONT:\n    input: test_data/assembly/samplesONT.tsv \n    metaflye:\n      additionalParams: \" -i 1 \"\n      quality: \" --nano-raw \"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>SAMPLE  READS\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/interleaved.fq.gz\n</code></pre> <pre><code>SAMPLE  READS\nnano    https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/SRR16328449_qc.fq.gz\n</code></pre>"},{"location":"modules/assembly/#output","title":"Output","text":"<p>The output is a gzipped fasta file containing contigs.</p>"},{"location":"modules/assembly/#megahit","title":"Megahit","text":""},{"location":"modules/assembly/#error-handling","title":"Error Handling","text":"<p>On error with exit codes ([-9, 137, 247]) (e.g. due to memory restrictions), the tool is executed again with higher cpu and memory values. The memory and cpu values are in case of a retry selected based on the flavor with the next higher memory value. The highest possible cpu/memory value is restricted by the highest cpu/memory value of all flavors defined in the resource section  (see global configuration section). </p>"},{"location":"modules/assembly/#peak-memory-usage-prediction","title":"Peak memory usage prediction","text":"<p>Memory consumption of an assembler varies based on diversity. We trained a machine learning model on kmer frequencies and the nonpareil diversity index in order to be able to predict the memory peak consumption of megahit in our full pipeline mode. The required resources in order to run the assembler are thereby fitted to the resources that are actually needed for a specific dataset. If this mode is enabled then Nonpareil and kmc that are part of the quality control module are automatically executed before the assembler run.  </p> <p>Please note that this mode is only tested for Megahit with default parameters and the meta-sensitive mode (<code>--presets meta-sensitive</code>).</p> <pre><code>  resources:\n    RAM: \n      mode: MODE\n      predictMinLabel: LABEL\n</code></pre> <p>where      * MODE can be either 'PREDICT' for predicting memory usage or 'DEFAULT' for using a default flavor defined in the resources section.</p> <pre><code>* LABEL is the flavor that will be used if the predicted RAM is below the memory value defined as part of the LABEL flavor. It can also be set to AUTO to always use the predicted flavor.\n</code></pre>"},{"location":"modules/cooccurrence/","title":"Cooccurrence","text":"<p>The Cooccurrence module builds a cooccurrence network where each node is a MAG and every edge represents an association between them. The network can be inferred based on correlation or inverse covariance estimation by SPIEC-EASI. SPIEC-EASI is executed multiple times based on different parameter settings in order to find the most stable network. In addition, it is possible to compute multiple metrics for every edge based on genome-scale metabolic models and the SMETANA metrics. </p> <pre><code>-entry wCooccurrence -params-file example_params/cooccurrence.yml\n</code></pre>"},{"location":"modules/cooccurrence/#input","title":"Input","text":"CommandConfiguration File for CooccurrenceTSV TableGTDB TSV TableConfiguration File for analyzing edges in Cooccurrence GraphGTDB TSV for analyzing EdgesModel TSV for computing Metabolomics Metrics on Edges <pre><code>-entry wCooccurrence -params-file example_params/cooccurrence.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the cooccurrence section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nrunid: 1\nlogLevel: 1\nlogDir: log\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  cooccurrence:\n    input:\n      gtdb: test_data/cooccurrence/gtdb.tsv\n      count: test_data/cooccurrence/counts.tsv \n    inference:\n       additionalParams: \n         method: 'correlation'\n         rscript: \" --mincovthreshold 0.1 --maxzero 110 --minweight 0.4 \"\n         timeLimit: \"AUTO\"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p><pre><code>SAMPLE  READS\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/interleaved.fq.gz\n</code></pre> Contains abundance values of mags per sample.</p> <p><pre><code>BIN_ID  DOMAIN  SAMPLE  user_genome classification  fastani_reference   fastani_reference_radius    fastani_taxonomy    fastani_ani fastani_af  closest_placement_reference closest_placement_radius    closest_placement_taxonomy  closest_placement_ani   closest_placement_af    pplacer_taxonomy    classification_method   note    other_related_references(genome_id,species_name,radius,ANI,AF)  msa_percent translation_table   red_value   warnings\ntest1_bin.1.fa  BACTERIA    test2   test2_bin.1.fa  d__Bacteria;p__Actinobacteriota;c__Actinomycetia;o__Actinomycetales;f__Dermatophilaceae;g__Phycicoccus;s__Phycicoccus sp001428065   GCF_001428065.1 95.0    d__Bacteria;p__Actinobacteriota;c__Actinomycetia;o__Actinomycetales;f__Dermatophilaceae;g__Phycicoccus;s__Phycicoccus sp001428065   99.77   0.99    GCF_001428065.1 95.0    d__Bacteria;p__Actinobacteriota;c__Actinomycetia;o__Actinomycetales;f__Dermatophilaceae;g__Phycicoccus;s__Phycicoccus sp001428065   99.77   0.99    d__Bacteria;p__Actinobacteriota;c__Actinomycetia;o__Actinomycetales;f__Dermatophilaceae;g__Phycicoccus;s__  taxonomic classification defined by topology and ANI    topological placement and ANI have congruent species assignments    GCF_002846495.1, s__Phycicoccus duodecadis, 95.0, 90.33, 0.95; GCF_011383005.1, s__Phycicoccus sp011383005, 95.0, 82.92, 0.85; GCF_000720925.1, s__Phycicoccus jejuensis, 95.0, 82.49, 0.82; GCF_013201035.1, s__Phycicoccus sp013201035, 95.0, 82.18, 0.84; GCF_004025965.2, s__Phycicoccus sp004025965, 95.0, 81.96, 0.78; GCF_011326735.1, s__Phycicoccus endophyticus, 95.0, 81.12, 0.7 12.73   11  N/A N/A\ntest2_bin.2.fa  BACTERIA    test2   test2_bin.2.fa  d__Bacteria;p__Firmicutes_C;c__Negativicutes;o__Selenomonadales;f__Selenomonadaceae;g__Schwartzia;s__Schwartzia succinivorans   GCF_900129225.1 95.0    d__Bacteria;p__Firmicutes_C;c__Negativicutes;o__Selenomonadales;f__Selenomonadaceae;g__Schwartzia;s__Schwartzia succinivorans   99.97   1.0 GCF_900129225.1 95.0    d__Bacteria;p__Firmicutes_C;c__Negativicutes;o__Selenomonadales;f__Selenomonadaceae;g__Schwartzia;s__Schwartzia succinivorans   99.97   1.0 d__Bacteria;p__Firmicutes_C;c__Negativicutes;o__Selenomonadales;f__Selenomonadaceae;g__;s__ taxonomic classification defined by topology and ANI    topological placement and ANI have congruent species assignments    N/A 91.94   11  N/A N/A\n</code></pre> GTDB assignment of all samples that were produced by magAttributes module.</p> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the cooccurrence section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"/tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nrunid: 1\nlogLevel: 0\nlogDir: log\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  cooccurrence:\n     input:\n       gtdb: test_data/cooccurrence/gtdb_large.tsv\n       count: test_data/cooccurrence/countsMedium.tsv\n       models: test_data/cooccurrence/models.tsv\n     inference:\n        additionalParams:\n          method: 'spiec-easi'\n          rscript: \" --mincovthreshold 0.1 --maxzero 110\"\n          timeLimit: \"AUTO\"\n     metabolicAnnotation:\n       additionalParams:\n         metabolicEdgeBatches: 5\n         metabolicEdgeReplicates: 10\n         smetana: \" --flavor bigg \"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p><pre><code>DOMAIN  PHYLUM  CLASS   ORDER   FAMILY  GENUS   SPECIES BIN_ID\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592244_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592244_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592244_bin.11\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592244_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__JAGOEY01 s__ ERR2592244_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592244_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592244_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__ ERR2592244_bin.18\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592244_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__ ERR2592244_bin.20\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter cryaerophilus_A    ERR2592244_bin.23\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__Pseudomonas_E paracarnis ERR2592244_bin.25\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592244_bin.26\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__Kaistella chaponensis    ERR2592244_bin.27\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592244_bin.28\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter celticus   ERR2592244_bin.29\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592244_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__Psychrobacter faecalis   ERR2592244_bin.32\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592244_bin.33\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592244_bin.34\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter johnsonii  ERR2592244_bin.36\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592244_bin.37\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Diaphorobacter_A s__ ERR2592244_bin.38\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592244_bin.4\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister sp000434475    ERR2592244_bin.40\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Micrococcaceae   g__Galactobacter    s__ ERR2592244_bin.41\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592244_bin.5\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__ ERR2592244_bin.6\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__ ERR2592244_bin.7\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592244_bin.8\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592244_bin.9\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Epilithonimonas  s__Epilithonimonas vandammei    ERR2592245_bin.11\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Empedobacter s__Empedobacter falsenii_A  ERR2592245_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter parvus ERR2592245_bin.13\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__ ERR2592245_bin.14\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592245_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia beijingensis ERR2592245_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter harbinensis    ERR2592245_bin.17\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__Streptococcus parasuis   ERR2592245_bin.18\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592245_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592245_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__26B  s__26B sp016894345  ERR2592245_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter johnsonii  ERR2592245_bin.21\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter harbinensis    ERR2592245_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592245_bin.23\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__Comamonas denitrificans_A    ERR2592245_bin.26\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter guillouiae ERR2592245_bin.27\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592245_bin.28\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus sulfidivorans   ERR2592245_bin.29\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__ ERR2592245_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__ ERR2592245_bin.30\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592245_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592245_bin.5\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__Moraxella_A sp002478835  ERR2592245_bin.6\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Vitreoscilla s__ ERR2592245_bin.8\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017997335   ERR2592245_bin.9\nd__Bacteria p__Verrucomicrobiota    c__Kiritimatiellae  o__LD1-PB3  f__Lenti-01 g__Lenti-01 s__ ERR2592249_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592249_bin.11\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia beijingensis ERR2592249_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592249_bin.13\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Acidaminococcales    f__Acidaminococcaceae   g__RZYP01   s__ ERR2592249_bin.14\nd__Bacteria p__Chloroflexota    c__Anaerolineae o__Promineofilales  f__Promineofilaceae g__Promineofilum    s__ ERR2592249_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592249_bin.16\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__UBA1444  f__UBA1444  g__UBA1444  s__ ERR2592249_bin.18\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__Desulfobulbus sp017998195    ERR2592249_bin.19\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__ s__ ERR2592249_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__ s__ ERR2592249_bin.21\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp017996515  ERR2592249_bin.22\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Peptostreptococcales f__Filifactoraceae  g__Acetoanaerobium  s__Acetoanaerobium noterae  ERR2592249_bin.23\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__ ERR2592249_bin.25\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__ ERR2592249_bin.27\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOWQ01 s__ ERR2592249_bin.28\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592249_bin.29\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592249_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter towneri    ERR2592249_bin.30\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Pasteurellaceae  g__Mesocricetibacter    s__ ERR2592249_bin.31\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592249_bin.33\nd__Bacteria p__Planctomycetota  c__Planctomycetia   o__Pirellulales f__PNKZ01   g__ s__ ERR2592249_bin.34\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Rhodocyclaceae   g__Propionivibrio   s__ ERR2592249_bin.36\nd__Bacteria p__Patescibacteria  c__Microgenomatia   o__UBA1406  f__ g__ s__ ERR2592249_bin.37\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp018054915  ERR2592249_bin.38\nd__Bacteria p__Acidobacteriota  c__Aminicenantia    o__ f__ g__ s__ ERR2592249_bin.39\nd__Bacteria p__Actinobacteriota c__Acidimicrobiia   o__Acidimicrobiales f__JAEUJM01 g__ s__ ERR2592249_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Klebsiella   s__Klebsiella pneumoniae    ERR2592249_bin.6\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592249_bin.7\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella    s__ ERR2592249_bin.8\nd__Bacteria p__Patescibacteria  c__JAEDAM01 o__BD1-5    f__UBA2023  g__UBA5532  s__ ERR2592251_bin.1\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592251_bin.10\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Chitinophagales  f__Chitinophagaceae g__Niabella s__ ERR2592251_bin.11\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592251_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__Psychrobacter maritimus  ERR2592251_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Thermomonas  s__ ERR2592251_bin.14\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592251_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592251_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__ s__ ERR2592251_bin.18\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592251_bin.19\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter acticola   ERR2592251_bin.2\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Fimenecus    s__Fimenecus sp000432435    ERR2592251_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Thermomonas  s__ ERR2592251_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592251_bin.4\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592251_bin.6\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592251_bin.7\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592251_bin.8\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592251_bin.9\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__Comamonas denitrificans_A    ERR2592252_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592252_bin.11\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__Leptotrichia_A   s__ ERR2592252_bin.12\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Acidaminococcales    f__Acidaminococcaceae   g__RZYP01   s__ ERR2592252_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__ ERR2592252_bin.14\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Propionibacteriales  f__Propionibacteriaceae g__Brooklawnia  s__ ERR2592252_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__JAABTG01 f__JAABTG01 g__JAGNLM01 s__ ERR2592252_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592252_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter towneri    ERR2592252_bin.18\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Veillonellaceae  g__Veillonella  s__Veillonella sp009929605  ERR2592252_bin.19\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Acidaminococcales    f__Acidaminococcaceae   g__RZYP01   s__ ERR2592252_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592252_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Rhodocyclaceae   g__ s__ ERR2592252_bin.21\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592252_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella    s__Moraxella porci  ERR2592252_bin.23\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp012729605  ERR2592252_bin.24\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__Desulfobulbus sp017998195    ERR2592252_bin.25\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Pasteurellaceae  g__Actinobacillus   s__ ERR2592252_bin.26\nd__Bacteria p__Verrucomicrobiota    c__Kiritimatiellae  o__RFP12    f__UBA3636  g__JAAZAI01 s__JAAZAI01 sp012514445 ERR2592252_bin.27\nd__Bacteria p__Acidobacteriota  c__Aminicenantia    o__ f__ g__ s__ ERR2592252_bin.28\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__Moraxella_A sp002478835  ERR2592252_bin.29\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592252_bin.3\nd__Bacteria p__Chloroflexota    c__Anaerolineae o__Anaerolineales   f__Anaerolineaceae  g__T78  s__ ERR2592252_bin.30\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592252_bin.31\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592252_bin.32\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp018054915  ERR2592252_bin.33\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia beijingensis ERR2592252_bin.34\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella    s__ ERR2592252_bin.35\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus sulfidivorans   ERR2592252_bin.36\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__ s__ ERR2592252_bin.37\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592252_bin.38\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Diaphorobacter   s__ ERR2592252_bin.40\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__Streptococcus parasuis   ERR2592252_bin.41\nd__Bacteria p__Synergistota c__Synergistia  o__Synergistales    f__Synergistaceae   g__Syner-03 s__Syner-03 sp002316795 ERR2592252_bin.42\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter cryaerophilus_A    ERR2592252_bin.43\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592252_bin.44\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas chironomi    ERR2592252_bin.45\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas denitrificans    ERR2592252_bin.47\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Pseudoxanthomonas    s__ ERR2592252_bin.49\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp017993135  ERR2592252_bin.5\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592252_bin.50\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella    s__ ERR2592252_bin.51\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Rhodocyclaceae   g__Azonexus s__Azonexus sp012839675 ERR2592252_bin.52\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592252_bin.53\nd__Bacteria p__Patescibacteria  c__Saccharimonadia  o__Saccharimonadales    f__Nanogingivalaceae    g__Nanogingivalis   s__ ERR2592252_bin.54\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Paludibacteraceae    g__UPXZ01   s__UPXZ01 sp009929445   ERR2592252_bin.55\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Pasteurellaceae  g__Mesocricetibacter    s__ ERR2592252_bin.6\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592252_bin.7\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Pseudoxanthomonas_A  s__ ERR2592252_bin.8\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592252_bin.9\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592253_bin.1\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592253_bin.10\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__ ERR2592253_bin.11\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__ ERR2592253_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592253_bin.13\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592253_bin.14\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__JAAFJR01 s__JAAFJR01 sp016705065 ERR2592253_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__Moraxella_A sp002478835  ERR2592253_bin.16\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__UJ101    g__UJ101    s__ ERR2592253_bin.17\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592253_bin.18\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592253_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592253_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592253_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__Comamonas denitrificans_A    ERR2592253_bin.21\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__DTU049   g__DTU049   s__DTU049 sp001513285   ERR2592253_bin.22\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Dermatophilaceae g__Phycicoccus_A    s__Phycicoccus_A elongatus  ERR2592253_bin.23\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592253_bin.24\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter sp017996075    ERR2592253_bin.25\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592253_bin.27\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__ ERR2592253_bin.29\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592253_bin.3\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Cellulomonadaceae    g__Timonella    s__ ERR2592253_bin.30\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Fimenecus    s__Fimenecus sp000432435    ERR2592253_bin.31\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Dermatophilaceae g__Phycicoccus_A    s__ ERR2592253_bin.33\nd__Bacteria p__Coprothermobacterota c__Coprothermobacteria  o__Coprothermobacterales    f__Coprothermobacteraceae   g__Coprothermobacter    s__Coprothermobacter proteolyticus  ERR2592253_bin.35\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__JAGOZY01 f__JAGOZY01 g__JAGOHU01 s__JAGOHU01 sp017995975 ERR2592253_bin.37\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Empedobacter s__ ERR2592253_bin.38\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592253_bin.39\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__Sebaldella   s__ ERR2592253_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__CTSOIL-112 sp017986195   ERR2592253_bin.40\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter sp009707625    ERR2592253_bin.5\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Sulfurospirillaceae  g__Sulfurospirillum s__ ERR2592253_bin.6\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__JAGOEY01 s__JAGOEY01 sp017997515 ERR2592253_bin.7\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592253_bin.8\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp017993135  ERR2592253_bin.9\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Lactobacillaceae g__Lactobacillus    s__Lactobacillus delbrueckii    ERR2592258_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp018054915  ERR2592258_bin.11\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Bacteroidaceae   g__Prevotella   s__Prevotella sp015074785   ERR2592258_bin.12\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister succinatiphilus    ERR2592258_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Aeromonadaceae   g__JAGOXX01 s__ ERR2592258_bin.16\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Acidaminococcales    f__Acidaminococcaceae   g__RZYP01   s__ ERR2592258_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Aeromonadaceae   g__JAGOXX01 s__ ERR2592258_bin.18\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Veillonellaceae  g__Veillonella_A    s__Veillonella_A sp900765165    ERR2592258_bin.19\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Butyrivibrio s__ ERR2592258_bin.2\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Veillonellaceae  g__Veillonella  s__Veillonella sp009929605  ERR2592258_bin.21\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Succinivibrionaceae  g__Succinivibrio    s__Succinivibrio sp000431835    ERR2592258_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Aeromonadaceae   g__Tolumonas    s__Tolumonas sp008015085    ERR2592258_bin.23\nd__Bacteria p__Actinobacteriota c__Coriobacteriia   o__Coriobacteriales f__Atopobiaceae g__Olsenella_D  s__Olsenella_D sp002331575  ERR2592258_bin.25\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__ s__ ERR2592258_bin.26\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592258_bin.27\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Escherichia  s__Escherichia coli ERR2592258_bin.28\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Sulfurospirillaceae  g__Sulfurospirillum s__Sulfurospirillum sp001548035 ERR2592258_bin.29\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus  s__Lactococcus lactis   ERR2592258_bin.3\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Anaeromusales    f__Anaeromusaceae   g__Anaeromusa   s__ ERR2592258_bin.30\nd__Bacteria p__Desulfobacterota_I   c__Desulfovibrionia o__Desulfovibrionales   f__Desulfovibrionaceae  g__Desulfovibrio    s__ ERR2592258_bin.31\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Bacteroidaceae   g__Prevotella   s__Prevotella copri_A   ERR2592258_bin.32\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Klebsiella   s__Klebsiella pneumoniae    ERR2592258_bin.33\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592258_bin.34\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__Megamonas    s__Megamonas funiformis ERR2592258_bin.35\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592258_bin.36\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium thermophilum ERR2592258_bin.37\nd__Bacteria p__Patescibacteria  c__Saccharimonadia  o__Saccharimonadales    f__Nanosyncoccaceae g__UBA2834  s__ ERR2592258_bin.38\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__Mitsuokella  s__Mitsuokella multacida    ERR2592258_bin.39\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__UBA932   g__Egerieousia  s__ ERR2592258_bin.4\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium adolescentis ERR2592258_bin.40\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium longum   ERR2592258_bin.42\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Tannerellaceae   g__Macellibacteroides   s__ ERR2592258_bin.43\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Bacteroidaceae   g__Prevotella   s__ ERR2592258_bin.44\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__ g__ s__ ERR2592258_bin.45\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Rikenellaceae    g__Alistipes    s__Alistipes putredinis ERR2592258_bin.46\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium sp002742445  ERR2592258_bin.47\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter cryaerophilus_A    ERR2592258_bin.48\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Bacteroidaceae   g__Prevotella   s__Prevotella sp018054505   ERR2592258_bin.5\nd__Bacteria p__Acidobacteriota  c__Aminicenantia    o__ f__ g__ s__ ERR2592258_bin.50\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Paludibacteraceae    g__ s__ ERR2592258_bin.51\nd__Bacteria p__Acidobacteriota  c__Mor1 o__J045 f__J045 g__JAGOJY01 s__ ERR2592258_bin.52\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592258_bin.54\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__ s__ ERR2592258_bin.55\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592258_bin.56\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__ ERR2592258_bin.57\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__Selenomonas_A    s__Selenomonas_A sp018052705    ERR2592258_bin.58\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592258_bin.6\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592258_bin.7\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__UBA932   g__Egerieousia  s__ ERR2592258_bin.8\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__ s__ ERR2592258_bin.9\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592260_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Hydromonas   s__ ERR2592260_bin.11\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__UBA2334  s__ ERR2592260_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter sp003987695    ERR2592260_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus montanus    ERR2592260_bin.14\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017997335   ERR2592260_bin.15\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592260_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592260_bin.17\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592260_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__JAGOEY01 s__ ERR2592260_bin.2\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017995345   ERR2592260_bin.20\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592260_bin.21\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Giesbergeria s__ ERR2592260_bin.23\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592260_bin.24\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus sulfidivorans   ERR2592260_bin.25\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus sulfidivorans   ERR2592260_bin.26\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter parvus ERR2592260_bin.3\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592260_bin.4\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__Kaistella chaponensis    ERR2592260_bin.7\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__Cloacibacterium caeni_A  ERR2592260_bin.8\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__Moraxella_A sp002478835  ERR2592260_bin.9\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592262_bin.1\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__Cloacibacterium caeni_A  ERR2592262_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592262_bin.4\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592262_bin.5\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592262_bin.6\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp018054915  ERR2592264_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Thiotrichales    f__Thiotrichaceae   g__ s__ ERR2592264_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Pseudoxanthomonas_A  s__ ERR2592264_bin.12\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592264_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592264_bin.14\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592264_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Thiotrichales    f__Thiotrichaceae   g__ s__ ERR2592264_bin.16\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592264_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Escherichia  s__Escherichia coli ERR2592264_bin.18\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592264_bin.19\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592264_bin.2\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium adolescentis ERR2592264_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Klebsiella   s__Klebsiella pneumoniae    ERR2592264_bin.21\nd__Bacteria p__Firmicutes   c__Bacilli  o__Erysipelotrichales   f__Coprobacillaceae g__Catenibacterium  s__Catenibacterium sp000437715  ERR2592264_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter parvus ERR2592264_bin.24\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Sphaerotilus s__Sphaerotilus sulfidivorans   ERR2592264_bin.25\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592264_bin.26\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter cryaerophilus_A    ERR2592264_bin.27\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Fimenecus    s__Fimenecus sp000432435    ERR2592264_bin.28\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592264_bin.29\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Blautia_A    s__Blautia_A wexlerae   ERR2592264_bin.30\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__ ERR2592264_bin.31\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Epilithonimonas  s__ ERR2592264_bin.32\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__Megamonas    s__Megamonas funiformis ERR2592264_bin.5\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__Selenomonadaceae g__Megamonas    s__Megamonas funiformis ERR2592264_bin.7\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Thiotrichales    f__Thiotrichaceae   g__ s__ ERR2592264_bin.8\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592264_bin.9\nd__Bacteria p__Desulfobacterota c__Syntrophia   o__Syntrophales f__UBA5619  g__UBA5619  s__ ERR2592265_bin.1\nd__Bacteria p__Desulfobacterota c__Syntrophia   o__Syntrophales f__Fen-1087 g__Fen-1087 s__ ERR2592265_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__JAABTG01 f__JAABTG01 g__JAGNLM01 s__ ERR2592265_bin.11\nd__Bacteria p__Synergistota c__Synergistia  o__Synergistales    f__Synergistaceae   g__Syner-03 s__Syner-03 sp002316795 ERR2592265_bin.13\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592265_bin.14\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__UBA1444  f__UBA1444  g__UBA1444  s__ ERR2592265_bin.15\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592265_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp012729605  ERR2592265_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592265_bin.18\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592265_bin.19\nd__Bacteria p__UBA1439  c__UBA1439  o__UBA1439  f__UBA1439  g__UBA1439  s__UBA1439 sp002329605  ERR2592265_bin.20\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Eisenbergiella   s__Eisenbergiella sp900066775   ERR2592265_bin.21\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592265_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas denitrificans    ERR2592265_bin.23\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Ruminococcaceae  g__Gemmiger s__Gemmiger qucibialis  ERR2592265_bin.24\nd__Bacteria p__Verrucomicrobiota    c__Verrucomicrobiae o__Verrucomicrobiales   f__SLCJ01   g__ s__ ERR2592265_bin.25\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Pseudoxanthomonas    s__Pseudoxanthomonas sp018060215    ERR2592265_bin.26\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592265_bin.27\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas chironomi    ERR2592265_bin.28\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium adolescentis ERR2592265_bin.29\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister hominis    ERR2592265_bin.3\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Escherichia  s__Escherichia coli ERR2592265_bin.30\nd__Bacteria p__Verrucomicrobiota    c__Kiritimatiellae  o__LD1-PB3  f__Lenti-01 g__Lenti-01 s__ ERR2592265_bin.4\nd__Bacteria p__Verrucomicrobiota    c__Verrucomicrobiae o__Verrucomicrobiales   f__Akkermansiaceae  g__Akkermansia  s__Akkermansia muciniphila  ERR2592265_bin.5\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592265_bin.6\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia beijingensis ERR2592265_bin.8\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__Desulfobulbus sp017998195    ERR2592265_bin.9\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592268_bin.1\nd__Bacteria p__Firmicutes_E c__DTU015   o__D8A-2    f__D2   g__UBA3907  s__UBA3907 sp018052475  ERR2592268_bin.10\nd__Bacteria p__Synergistota c__Synergistia  o__Synergistales    f__Synergistaceae   g__Syner-03 s__Syner-03 sp002306075 ERR2592268_bin.12\nd__Bacteria p__Synergistota c__Synergistia  o__Synergistales    f__Synergistaceae   g__ s__ ERR2592268_bin.13\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Paludibacteraceae    g__UPXZ01   s__ ERR2592268_bin.14\nd__Bacteria p__Patescibacteria  c__Dojkabacteria    o__B142 f__OLB20    g__ s__ ERR2592268_bin.15\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Fimenecus    s__Fimenecus sp000432435    ERR2592268_bin.16\nd__Bacteria p__Verrucomicrobiota    c__Verrucomicrobiae o__Verrucomicrobiales   f__Akkermansiaceae  g__Akkermansia  s__Akkermansia muciniphila  ERR2592268_bin.19\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__ ERR2592268_bin.2\nd__Bacteria p__Patescibacteria  c__Saccharimonadia  o__Saccharimonadales    f__JAGPDM01 g__JAGPDM01 s__ ERR2592268_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Pseudoxanthomonas_A  s__ ERR2592268_bin.21\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592268_bin.23\nd__Bacteria p__Actinobacteriota c__Acidimicrobiia   o__Acidimicrobiales f__Microtrichaceae  g__Microthrix   s__ ERR2592268_bin.25\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Fimenecus    s__Fimenecus sp000432435    ERR2592268_bin.26\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__Cloacibacterium caeni_A  ERR2592268_bin.27\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Tissierellales   f__Peptoniphilaceae g__JAAYEL01 s__ ERR2592268_bin.28\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__ ERR2592268_bin.29\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Bifidobacteriaceae   g__Bifidobacterium  s__Bifidobacterium adolescentis ERR2592268_bin.3\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Dysgonomonadaceae    g__UBA5287  s__ ERR2592268_bin.30\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Peptostreptococcales f__Filifactoraceae  g__Proteocatella    s__Proteocatella sp009929415    ERR2592268_bin.31\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__Paludibacteraceae    g__UPXZ01   s__ ERR2592268_bin.32\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Acidaminococcales    f__Acidaminococcaceae   g__ s__ ERR2592268_bin.33\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__JAGOGN01 s__ ERR2592268_bin.34\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Ruminococcaceae  g__Gemmiger s__Gemmiger qucibialis  ERR2592268_bin.35\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__Psychrobacter faecalis   ERR2592268_bin.36\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592268_bin.37\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__UBA4417  g__UBA4417  s__ ERR2592268_bin.38\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__Comamonas denitrificans_A    ERR2592268_bin.39\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia sp018060485  ERR2592268_bin.40\nd__Bacteria p__Patescibacteria  c__ABY1 o__BM507    f__UBA917   g__UBA1359  s__ ERR2592268_bin.41\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Enterococcaceae  g__Enterococcus_I   s__Enterococcus_I aquimarinus   ERR2592268_bin.42\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp017993135  ERR2592268_bin.43\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592268_bin.44\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592268_bin.45\nd__Bacteria p__Patescibacteria  c__Dojkabacteria    o__SC72 f__SC72 g__ s__ ERR2592268_bin.46\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592268_bin.47\nd__Bacteria p__Patescibacteria  c__Paceibacteria    o__UBA6257  f__ g__ s__ ERR2592268_bin.48\nd__Bacteria p__Patescibacteria  c__Saccharimonadia  o__Saccharimonadales    f__UBA7683  g__ s__ ERR2592268_bin.49\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592268_bin.5\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter johnsonii  ERR2592268_bin.50\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592268_bin.6\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Peptostreptococcales f__Filifactoraceae  g__Proteocatella    s__ ERR2592268_bin.7\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Tissierellales   f__Peptoniphilaceae g__JAAYEL01 s__ ERR2592268_bin.8\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592268_bin.9\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592269_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592269_bin.11\nd__Bacteria p__Caldisericota    c__Caldisericia o__Caldisericales   f__Caldisericaceae  g__ s__ ERR2592269_bin.12\nd__Bacteria p__Chloroflexota    c__Anaerolineae o__Anaerolineales   f__Anaerolineaceae  g__ s__ ERR2592269_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Pasteurellaceae  g__Glaesserella s__ ERR2592269_bin.14\nd__Bacteria p__Desulfobacterota c__Syntrophia   o__Syntrophales f__UBA5619  g__UBA5619  s__ ERR2592269_bin.16\nd__Bacteria p__Verrucomicrobiota    c__Kiritimatiellae  o__LD1-PB3  f__Lenti-01 g__Lenti-01 s__ ERR2592269_bin.17\nd__Bacteria p__Bacteroidota c__Ignavibacteria   o__SJA-28   f__B-1AR    g__CAIKZJ01 s__ ERR2592269_bin.18\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Bacteroidales    f__VadinHA17    g__SR-FBR-E99   s__SR-FBR-E99 sp018262715   ERR2592269_bin.19\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__ ERR2592269_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__CTSOIL-112   s__ ERR2592269_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Enterobacteriaceae   g__Klebsiella   s__Klebsiella quasipneumoniae   ERR2592269_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__JAABTG01 f__JAABTG01 g__JAGNLM01 s__ ERR2592269_bin.23\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Rhodanobacteraceae   g__ s__ ERR2592269_bin.24\nd__Bacteria p__Desulfobacterota c__Syntrophia   o__Syntrophales f__Fen-1087 g__Fen-1087 s__ ERR2592269_bin.25\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Xanthomonadales  f__Xanthomonadaceae g__Thermomonas  s__ ERR2592269_bin.26\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592269_bin.28\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Casimicrobiaceae g__VBCG01   s__ ERR2592269_bin.29\nd__Bacteria p__UBA1439  c__UBA1439  o__UBA1439  f__UBA1439  g__UBA1439  s__UBA1439 sp002329605  ERR2592269_bin.3\nd__Bacteria p__Spirochaetota    c__JAAYUW01 o__JAAYUW01 f__JAAYUW01 g__Exilispira   s__ ERR2592269_bin.30\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592269_bin.32\nd__Bacteria p__Desulfobacterota c__Syntrophia   o__Syntrophales f__Smithellaceae    g__UBA8904  s__UBA8904 sp002070455  ERR2592269_bin.35\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp018054915  ERR2592269_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter harbinensis    ERR2592269_bin.5\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592269_bin.7\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Tissierellales   f__Sedimentibacteraceae g__Sedimentibacter  s__Sedimentibacter sp017995755  ERR2592269_bin.8\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter parvus ERR2592269_bin.9\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017997335   ERR2592273_bin.1\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter pullicarnis    ERR2592273_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592273_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__ ERR2592273_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter harbinensis    ERR2592273_bin.14\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592273_bin.15\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592273_bin.16\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter acticola   ERR2592273_bin.17\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592273_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__ ERR2592273_bin.2\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__Acinetobacter celticus   ERR2592273_bin.20\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592273_bin.21\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592273_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__ ERR2592273_bin.26\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592273_bin.27\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Evansiales   f__ g__ s__ ERR2592273_bin.28\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__ ERR2592273_bin.3\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Bergeyella_A s__ ERR2592273_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__ ERR2592273_bin.5\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Microbacteriaceae    g__ s__ ERR2592273_bin.6\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017989775   ERR2592273_bin.7\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__Kaistella chaponensis    ERR2592273_bin.8\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Psychrobacter    s__Psychrobacter faecalis   ERR2592273_bin.9\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__ ERR2592274_bin.1\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Mycobacteriales  f__Mycobacteriaceae g__Rhodococcus  s__Rhodococcus qingshengii  ERR2592274_bin.11\nd__Bacteria p__Actinobacteriota c__Actinomycetia    o__Actinomycetales  f__Dermatophilaceae g__Ornithinibacter  s__Ornithinibacter sp017989115  ERR2592274_bin.12\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Formosimonas s__ ERR2592274_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax defluvii  ERR2592274_bin.14\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592274_bin.15\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Lactococcus_A    s__Lactococcus_A raffinolactis  ERR2592274_bin.16\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__JAGOEY01 s__ ERR2592274_bin.17\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__JAGOYM01 sp018059165 ERR2592274_bin.18\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella_A  s__Moraxella_A sp002478835  ERR2592274_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592274_bin.2\nd__Bacteria p__Chloroflexota    c__Anaerolineae o__Anaerolineales   f__Anaerolineaceae  g__Brevefilum   s__Brevefilum fermentans    ERR2592274_bin.20\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Ruminococcaceae  g__Faecalibacterium s__Faecalibacterium prausnitzii_G   ERR2592274_bin.21\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Kaistella    s__Kaistella chaponensis    ERR2592274_bin.22\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Flavobacteriaceae    g__Flavobacterium   s__Flavobacterium sp017997335   ERR2592274_bin.23\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Aerococcaceae    g__Trichococcus s__Trichococcus flocculiformis  ERR2592274_bin.25\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__ ERR2592274_bin.26\nd__Bacteria p__Firmicutes_A c__Clostridia   o__TANB77   f__CAG-508  g__CAG-273  s__ ERR2592274_bin.27\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Acutalibacteraceae   g__Ruminococcus_E   s__Ruminococcus_E sp003526955   ERR2592274_bin.3\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592274_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Hydromonas   s__ ERR2592274_bin.5\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Acinetobacter    s__ ERR2592274_bin.6\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592274_bin.9\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__ ERR2592276_bin.1\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__Streptococcus parasuis   ERR2592276_bin.10\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__Neisseria suis   ERR2592276_bin.11\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__ ERR2592276_bin.12\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__Sebaldella   s__Sebaldella termitidis    ERR2592276_bin.13\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Comamonas    s__Comamonas denitrificans_A    ERR2592276_bin.14\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Ruminococcaceae  g__Gemmiger s__Gemmiger qucibialis  ERR2592276_bin.16\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__ ERR2592276_bin.17\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Peptostreptococcales f__Filifactoraceae  g__Proteocatella    s__Proteocatella sp009929415    ERR2592276_bin.18\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592276_bin.19\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Acidovorax   s__Acidovorax temperans ERR2592276_bin.2\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Agathobacter s__Agathobacter rectalis    ERR2592276_bin.20\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Enterobacterales f__Pasteurellaceae  g__Chelonobacter    s__ ERR2592276_bin.21\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Veillonellales   f__Dialisteraceae   g__Dialister    s__Dialister invisus    ERR2592276_bin.22\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Moraxellaceae    g__Moraxella    s__ ERR2592276_bin.23\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Brachymonas  s__Brachymonas sp017996515  ERR2592276_bin.24\nd__Bacteria p__Bacteroidota c__Bacteroidia  o__Flavobacteriales f__Weeksellaceae    g__Cloacibacterium  s__Cloacibacterium caeni_A  ERR2592276_bin.27\nd__Bacteria p__Campylobacterota c__Campylobacteria  o__Campylobacterales    f__Arcobacteraceae  g__Aliarcobacter    s__Aliarcobacter cryaerophilus_A    ERR2592276_bin.28\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Blautia_A    s__Blautia_A wexlerae   ERR2592276_bin.29\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Burkholderiaceae g__Ottowia  s__Ottowia beijingensis ERR2592276_bin.3\nd__Bacteria p__Firmicutes_C c__Negativicutes    o__Selenomonadales  f__JAGPMH01 g__JAGPMH01 s__JAGPMH01 sp018052945 ERR2592276_bin.30\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Lachnospirales   f__Lachnospiraceae  g__Eisenbergiella   s__Eisenbergiella sp900066775   ERR2592276_bin.31\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Oscillospirales  f__Ruminococcaceae  g__Faecalibacterium s__Faecalibacterium prausnitzii_C   ERR2592276_bin.4\nd__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Burkholderiales  f__Neisseriaceae    g__Neisseria    s__ ERR2592276_bin.5\nd__Bacteria p__Firmicutes   c__Bacilli  o__Lactobacillales  f__Streptococcaceae g__Streptococcus    s__ ERR2592276_bin.6\nd__Bacteria p__Fusobacteriota   c__Fusobacteriia    o__Fusobacteriales  f__Leptotrichiaceae g__JAGOYM01 s__ ERR2592276_bin.7\nd__Bacteria p__Firmicutes_A c__Clostridia   o__Peptostreptococcales f__Filifactoraceae  g__Acetoanaerobium  s__Acetoanaerobium noterae  ERR2592276_bin.8\nd__Bacteria p__Desulfobacterota c__Desulfobulbia    o__Desulfobulbales  f__Desulfobulbaceae g__Desulfobulbus    s__ ERR2592276_bin.9\n</code></pre> GTDB assignment of all samples that were produced by the magAttributes module.</p> <pre><code>BIN_ID  PATH\nERR2592244_bin.27   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592244_bin.27.fa.xml\nERR2592244_bin.33   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592244_bin.33.fa.xml\nERR2592245_bin.18   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592245_bin.18.fa.xml\nERR2592249_bin.19   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.19.fa.xml\nERR2592249_bin.25   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.25.fa.xml\nERR2592249_bin.27   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.27.fa.xml\nERR2592249_bin.29   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.29.fa.xml\nERR2592249_bin.31   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.31.fa.xml\nERR2592249_bin.38   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592249_bin.38.fa.xml\nERR2592251_bin.11   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592251_bin.11.fa.xml\nERR2592251_bin.12   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592251_bin.12.fa.xml\nERR2592251_bin.13   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592251_bin.13.fa.xml\nERR2592252_bin.11   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.11.fa.xml\nERR2592252_bin.16   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.16.fa.xml\nERR2592252_bin.19   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.19.fa.xml\nERR2592252_bin.25   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.25.fa.xml\nERR2592252_bin.35   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.35.fa.xml\nERR2592252_bin.44   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.44.fa.xml\nERR2592252_bin.5    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.5.fa.xml\nERR2592252_bin.6    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592252_bin.6.fa.xml\nERR2592253_bin.11   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.11.fa.xml\nERR2592253_bin.13   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.13.fa.xml\nERR2592253_bin.23   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.23.fa.xml\nERR2592253_bin.35   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.35.fa.xml\nERR2592253_bin.37   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.37.fa.xml\nERR2592253_bin.4    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.4.fa.xml\nERR2592253_bin.6    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.6.fa.xml\nERR2592253_bin.9    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592253_bin.9.fa.xml\nERR2592258_bin.2    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592258_bin.2.fa.xml\nERR2592258_bin.21   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592258_bin.21.fa.xml\nERR2592258_bin.3    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592258_bin.3.fa.xml\nERR2592258_bin.5    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592258_bin.5.fa.xml\nERR2592258_bin.56   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592258_bin.56.fa.xml\nERR2592260_bin.16   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592260_bin.16.fa.xml\nERR2592262_bin.5    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592262_bin.5.fa.xml\nERR2592262_bin.6    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592262_bin.6.fa.xml\nERR2592264_bin.1    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592264_bin.1.fa.xml\nERR2592265_bin.11   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592265_bin.11.fa.xml\nERR2592265_bin.13   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592265_bin.13.fa.xml\nERR2592265_bin.7    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592265_bin.7.fa.xml\nERR2592265_bin.9    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592265_bin.9.fa.xml\nERR2592268_bin.23   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592268_bin.23.fa.xml\nERR2592268_bin.38   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592268_bin.38.fa.xml\nERR2592268_bin.45   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592268_bin.45.fa.xml\nERR2592269_bin.12   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592269_bin.12.fa.xml\nERR2592269_bin.19   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592269_bin.19.fa.xml\nERR2592269_bin.4    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592269_bin.4.fa.xml\nERR2592274_bin.18   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592274_bin.18.fa.xml\nERR2592274_bin.3    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592274_bin.3.fa.xml\nERR2592276_bin.23   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592276_bin.23.fa.xml\nERR2592276_bin.28   https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592276_bin.28.fa.xml\nERR2592276_bin.5    https://openstack.cebitec.uni-bielefeld.de:8080/meta_test/medium/cooccurrence/ERR2592276_bin.5.fa.xml\n</code></pre> <p>The following parameters can be configured:</p> <ul> <li> <p>metabolicEdgeBatches: Batches of edges that are provided as input to SMETANA.</p> </li> <li> <p>metabolicEdgeReplicates: Number of replicates per edge that should be computed.</p> </li> </ul>"},{"location":"modules/cooccurrence/#output","title":"Output","text":"<ul> <li> <p>output_raw.graphml: Cooccurrence network unfiltered in graphml format</p> </li> <li> <p>output.graphml: Filtered cooccurrence network in graphml format</p> </li> <li> <p>edges_index.tsv: Edges of the graph</p> </li> <li> <p>edgeAttributes.tsv: Edge attributes of the graph containing metrics computed by SMETANA.</p> </li> </ul>"},{"location":"modules/cooccurrence/#spiec-easi","title":"SPIEC-EASI","text":"<ul> <li>stability.txt: Network stability estimation</li> </ul>"},{"location":"modules/dereplication/","title":"Dereplication","text":""},{"location":"modules/dereplication/#input","title":"Input","text":"CommandConfiguration FileTSV Table <pre><code>-entry wDereplication -params-file example_params/dereplication.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the dereplication section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>output: \"output\"\nsummary: false\ns3SignIn: false\nrunid: 1\nlogLevel: 1\nlogDir: log\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  dereplication:\n    bottomUpClustering:\n      input: \"test_data/dereplication/input.tsv\"\n      minimumCompleteness: 0\n      maximumContamination: 5000\n      ANIBuffer: 20\n      mashBuffer: 2000\n      method: 'ANI'\n      additionalParams:\n        mash_sketch: \"\"\n        mash_dist: \"\"\n        #  cluster cutoff\n        cluster: \" -c 0.05 \"\n        pyani: \" -m ANIb \"\n        representativeAniCutoff: 0.95\n    sans:\n      additionalParams: \" -k 15 -f strict -w 25  -t 400 \" \nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p><pre><code>DATASET BIN_ID  PATH    COMPLETENESS    CONTAMINATION   COVERAGE    N50 HETEROGENEITY\ntest3   test3_bin.1 https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa    100 0   10  5000    10\ntest1   test1_bin.2 https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa    100 0   10  5000    10\ntest1   test1_bin.8 https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta 100 0   10  5000    10\ntest2   test2_bin.9 https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta 100 0   10  5000    10\ntest3   test2_bin.10    https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta 100 0   10  5000    10\ntest2   test2_bin.32    https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa   100 0   10  5000    10\n</code></pre> Must include the columns <code>DATASET</code>, <code>BIN_ID</code>, <code>PATH</code>, <code>COMPLETENESS</code>, <code>CONTAMINATION</code>, <code>COVERAGE</code>, <code>N50</code> and <code>HETEROGENEITY</code>.  Completeness and contamination can be used for filtering (see <code>params-file</code>). <code>N50</code>, <code>COVERAGE</code> and <code>HETEROGENEITY</code> are used for selecting the representative of every cluster. You can set values of these columns to zero if data is not available or if you don't want the representative selection to be influenced by theses columns. Make sure that <code>BIN_ID</code> is a unique identifier.</p>"},{"location":"modules/dereplication/#output","title":"Output","text":"<p>The output tsv file (<code>clusters.tsv</code>in the cluster's folder) contains the columns <code>CLUSTER</code>, <code>GENOME</code> and <code>REPRESENTATIVE</code> where <code>CLUSTER</code> identifies a group of genomes, <code>GENOME</code> represents the path or link of a genome and <code>REPRESENTATIVE</code> is either 0 or 1 (selected as representative). If <code>sans</code> is specified in the configuration file (see examples folder), then SANS is used to dereplicate the genomes of every cluster that was reported by the previous step.  The SANS output can be found in the <code>sans</code> folder.</p>"},{"location":"modules/export/","title":"Exploratory Metagenome Browser (EMGB)","text":"<p>The output generated by the Metagenomics-Toolkit can be imported into EMGB. EMGB allows you to easily explore your metagenomic samples in terms of MAGs, genes and their function.</p> <p>You can either directly specify the export to EMGB in your config file when you analyse your samples, or you can execute the export afterwards by running the Toolkit again with the export entry point. </p> <p>Currently, the export for EMGB needs the results of the following tools:</p> <ol> <li>Assembly</li> <li>Binning</li> <li>Checkm (v1 or v2)</li> <li>Prokka output</li> <li>GTDB-Tk </li> <li>MMseqs Taxonomy (Database: GTDB)</li> <li>MMseqs (Database: UniRef90) </li> </ol>"},{"location":"modules/export/#input","title":"Input","text":"CommandConfiguration File <pre><code>-entry wExportPipeline -params-file example_params/export.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the read mapping section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\ninput: \"output\"\noutput: \"output\"\nlogDir: log\nrunid: 1\ndatabases: \"/mnt/databases\"\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  export:\n    emgb:\n      additionalParams:\n              blastDB: \"bacmet20_predicted\"\n              taxonomyDB: \"gtdb\"\n      titles:\n        database:\n          download:\n            source: \"https://openstack.cebitec.uni-bielefeld.de:8080/databases/uniref90.titles.tsv.gz\"\n            md5sum: aaf1dd9021243def8e6c4e438b4b3669\n      kegg:\n        database:\n          download:\n            source: s3://databases_internal/annotatedgenes2json_db_kegg-mirror-2022-12.tar.zst\n            md5sum: 262dab8ca564fbc1f27500c22b5bc47b\n            s5cmd:\n              params: '--retry-count 30 --no-verify-ssl --endpoint-url https://openstack.cebitec.uni-bielefeld.de:8080'\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre>"},{"location":"modules/export/#additional-parameters","title":"Additional Parameters","text":"<ul> <li> <p>blastDB: The toolkit runs MMseqs against multiple databases. You can specify here, which BLAST output should be used. (Default: UniRef90)</p> </li> <li> <p>taxonomyDB: MMseqs is executed against a specific taxonomy database. (Default: GTDB)   </p> </li> </ul>"},{"location":"modules/export/#output","title":"Output","text":"<p>The following files are produced as output:</p> <ul> <li>SAMPLE.bins.json.gz  </li> <li>SAMPLE.contigs.json.gz</li> <li>SAMPLE.genes.json.gz</li> </ul> <p>where <code>SAMPLE</code> is the name of the sample.</p> <p>You can read more here about how to  start EMGB and use these files to import a dataset. </p>"},{"location":"modules/fragment_recruitment/","title":"Run Fragment Recruitment","text":"<p>The fragment recruitment module can be used to find genomes in a set of read datasets.</p> <p>In case the fragment recruitment module is part of the full pipeline pr per-sample pipeline configuration then reads that could not be mapped back to a contig are screened for a user provided list of MAGs. Detected genomes are included in all other parts of the remaining pipeline. Look out for their specific headers to differentiate results based on real assembled genomes and the reference genomes.</p> <p>Note: This module currently only supports illumina data. </p>"},{"location":"modules/fragment_recruitment/#input","title":"Input","text":"CommandConfiguration file for fragment recruitment via mash screen and BWAConfiguration file for fragment recruitment via mash screen and BowtieInput TSV file for genomesInput TSV file for paired end readsInput TSV file for single end reads <pre><code>-entry wFragmentRecruitment -params-file example_params/fragmentRecruitment.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the fragment recruitment section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  fragmentRecruitment:\n    mashScreen:\n      samples:\n        paired: test_data/fragmentRecruitment/paired.tsv\n        single: test_data/fragmentRecruitment/single.tsv\n      genomes: test_data/fragmentRecruitment/mags.tsv\n      unzip:\n        timeLimit: \"AUTO\"\n      additionalParams:\n        mashSketch: \" \"\n        mashScreen: \" \"\n        bwa2: \" \"\n        minimap: \" \"\n        coverm: \"  --min-covered-fraction 0  \"\n        covermONT: \"  --min-covered-fraction 0 \"\n        samtoolsViewBwa2: \" -F 3584 \" \n        samtoolsViewMinimap: \" \" \n      mashDistCutoff: 0.70\n      coveredBasesCutoff: 0.2\n      mashHashCutoff: 2\n    genomeCoverage:\n      additionalParams: \"\"\n    contigsCoverage:\n      additionalParams: \"\"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the fragment recruitment section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\nsteps:\n  fragmentRecruitment:\n    mashScreen:\n      samples:\n        paired: test_data/fragmentRecruitment/paired.tsv\n        single: test_data/fragmentRecruitment/single.tsv\n      genomes: test_data/fragmentRecruitment/mags.tsv\n      unzip:\n        timeLimit: \"AUTO\"\n      additionalParams:\n        mashSketch: \" \"\n        mashScreen: \" \"\n        bowtie: \" \"\n        minimap: \" \"\n        coverm: \"  --min-covered-fraction 0  \"\n        covermONT: \"  --min-covered-fraction 0  \"\n        samtoolsViewBowtie: \" -F 3584 \" \n        samtoolsViewMinimap: \" \" \n      mashDistCutoff: 0.70\n      coveredBasesCutoff: 0.2\n      mashHashCutoff: 2\n    genomeCoverage:\n      additionalParams: \"\"\n    contigsCoverage:\n      additionalParams: \"\"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>PATH\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/test234.fa\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa\n</code></pre> <pre><code>SAMPLE  READS\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/interleaved.fq.gz\ntest2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/interleaved.fq.gz\n</code></pre> <pre><code>SAMPLE  READS\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz\n</code></pre> <p>NOTE! The file names of all provided genomes must be unique.</p> <p>The following parameters can be configured:</p> <ul> <li> <p>mashDistCutoff: All hits below this threshold are  discarded.</p> </li> <li> <p>mashHashCutoff: All hits that have a lower count of matched minimum hashes are discarded.</p> </li> <li> <p>coveredBasesCutoff: Number of bases that must be covered by at least one read. By how many reads     the bases must be covered can be configured via the coverm setting (coverm: \"  --min-covered-fraction 0  \").</p> </li> </ul>"},{"location":"modules/fragment_recruitment/#output","title":"Output","text":"<p>The module outputs mash screen and bowtie alignment statistics.  Furthermore, the module provides a coverm output which basically reports all metrics about the found genomes (e.g covered bases,length, tpm, ...).</p>"},{"location":"modules/introduction/","title":"Introduction","text":"<p>Every module of the Metagenomics-Toolkit can be executed independent of any other module. This section defines the input YAML, input TSV file and the files that are output. The explanation of how to use the Toolkit and any configuration parameters can be found in the Getting Started and the Configuration section.</p>"},{"location":"modules/magAttributes/","title":"MagAttributes","text":""},{"location":"modules/magAttributes/#input","title":"Input","text":"CommandConfiguration FileMAGs TSV Table <pre><code>-entry wMagAttributes -params-file example_params/magAttributes.yml \n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the magAttributes section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: true\noutput: \"output\"\nlogDir: log\nrunid: 1\ns3SignIn: false\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  magAttributes:\n    input: \"test_data/magAttributes/input.tsv\"\n    gtdb:\n      buffer: 1000\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/gtdbtk_r214_data.tar.gz\n          md5sum: 390e16b3f7b0c4463eb7a3b2149261d9\n      additionalParams: \" --min_af 0.65 --scratch_dir . \"\n    checkm2:\n      database:\n        download:\n          source: \"https://openstack.cebitec.uni-bielefeld.de:8080/databases/checkm2_v2.tar.gz\"\n          md5sum: a634cb3d31a1f56f2912b74005f25f09\n      additionalParams: \"  \"\n    checkm:\n      database:\n        download:\n          source: \"https://openstack.cebitec.uni-bielefeld.de:8080/databases/checkm_data_2015_01_16.tar.gz\"\n          md5sum: 0963b301dfe9345ea4be1246e32f6728\n      buffer: 200\n      additionalParams:\n        tree: \" --reduced_tree \"\n        lineage_set: \" \" \n        qa: \"  \"\n    prokka:\n      defaultKingdom: false\n      additionalParams: \" --mincontiglen 200 \"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p><pre><code>DATASET BIN_ID  PATH    COMPLETENESS    CONTAMINATION   COVERAGE    N50 HETEROGENEITY\ntest1   bin.1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa    100 0   10  5000    10\ntest1   bin.2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa    100 0   10  5000    10\ntest1   bin.8   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta 100 0   10  5000    10\ntest2   bin.9   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta 100 0   10  5000    10\ntest2   bin.32  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa   100 0   10  5000    10\n</code></pre> Must include at least <code>DATASET</code> identifier and mag specific <code>PATH</code> and <code>BIN_ID</code> column.</p>"},{"location":"modules/magAttributes/#databases","title":"Databases","text":"<p>Checkm and GTDB need their databases as input. See database section for possibly download strategies. The GTDB and Checkm compressed databases must be tar.gz files. If you provide the extracted version of GTDB using the <code>extractedDBPath</code> parameter, please specify the path to the <code>releasesXXX</code> directory (e.g. \"/vol/spool/gtdb/release202\").</p> <p>If you need credentials to access your files via S3 then please use the following command:</p> <p>For GTDB: <pre><code>nextflow secrets set S3_gtdb_ACCESS XXXXXXX\nnextflow secrets set S3_gtdb_SECRET XXXXXXX\n</code></pre></p> <p>For Checkm: <pre><code>nextflow secrets set S3_checkm_ACCESS XXXXXXX\nnextflow secrets set S3_checkm_SECRET XXXXXXX\n</code></pre></p>"},{"location":"modules/magAttributes/#output","title":"Output","text":""},{"location":"modules/magAttributes/#gtdbtk","title":"GTDBTk","text":"<p>All GTDB files include the GTDB specific columns in addition to a <code>SAMPLE</code> column (<code>SAMPLE_gtdbtk.bac120.summary.tsv</code>, <code>SAMPLE_gtdbtk.ar122.summary.tsv</code>). In addition, this module produces a file <code>SAMPLE_gtdbtk_CHUNK.tsv</code> that combines both files and adds a <code>BIN_ID</code> column that adheres to the magAttributes specification</p>"},{"location":"modules/magAttributes/#checkm-and-checkm2","title":"Checkm and Checkm2","text":"<p>The Checkm and Checkm2 output adheres to the magAttributes specification and adds a <code>BIN_ID</code> and <code>SAMPLE</code> column to the output file. If Checkm2 and Checkm are both specified in the config file then only the Checkm2 results are used for downstream pipeline steps.</p>"},{"location":"modules/metabolomics/","title":"Metabolomics","text":"<p>The metabolomics module runs genome scale metabolic modeling analysis based on a supplied genome or directly on its proteins. The module is able to use gapseq and carveme for analysing genomes and carveme for analysing predicted proteins which depends on the configuration you provide as input.</p> <p>Note: If carvem is specificed in fullPipeline mode then carveme is executed with proteins as input.</p> <p>All generated models are used for further downstream analysis such as the \"Minimum Resource Overlap\" computation by smetana.</p>"},{"location":"modules/metabolomics/#input","title":"Input","text":"CommandConfiguration file for providing genomes <pre><code>-entry wMetabolomics -params-file example_params/metabolomics\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the metabolomics section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\ninput:\n  paired:\n    path: \"test_data/fullPipeline/reads_split.tsv\"\n    watch: false\noutput: \"output\"\nlogDir: log\nrunid: 1\ndatabases: \"/mnt/databases\"\nlogLevel: 1\nscratch: \"/vol/scratch\"\nsteps:\n  metabolomics:\n     input:\n       bins: \"test_data/metabolomics/input.tsv\" \n     filter:\n       minCompleteness: 49\n       maxContamination: 5\n     carveme:\n       additionalParams: \" --solver scip \"\n     smetana:\n       beforeProcessScript: /vol/spool/dockerPull.sh\n       global: true\n       detailed: true\n       additionalParams:\n         detailed: \"\"\n         global: \"\"\n     memote:\n       beforeProcessScript: /vol/spool/dockerPull.sh\n       additionalParams:\n         run: \"\"\n         report: \"\"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>Almost all tools of this module are using linear programming solvers. The tool developers are recommending the use of the cplex solver that is included in the IBM ILOG CPLEX Optimization Studio which is free for students and academics through the IBM Academic Initiative programm.  Since the toolkit uses docker images that are downloaded from public Docker Hub repositories and the cplex license is not allowed to be distributed, we prepared a Dockerfile (see <code>cplex/docker/Dockerfile</code> in the Github repository) that allows you to build your own local docker image with all metabolomics specific tools installed. Just copy your cplex binary to the cplex docker folder and build your own docker image. You can override all existing images via the command line.</p> <p>In the following example your the image name is metabolomics:0.1.0:</p> <ul> <li><code>--gapseq_image=metabolomics:0.1.0</code> (Optional)</li> <li><code>--smetana_image=metabolomics:0.1.0</code> (Required)</li> <li><code>--carveme_image=metabolomics:0.1.0</code> (Optional. Carveme is not able to detect the solver automatically. Please specify <code>--solver</code> in the configuration file if you want to use the scip solver.)</li> <li><code>--memote_image=metabolomics:0.1.0</code> (Optional. Memote is not able to detect the solver automatically. Please specify <code>--solver</code> in the configuration file if you are not using the glpk solver.)</li> </ul> <p>For gapseq and memote we are using a publicly available docker image that uses the freely available glkp solver which means that you don't have to provide this parameter. If you want to build your own image, please use the <code>beforeProcessScript</code> parameter. This parameter expects a bash script that accepts the docker image name as a parameter. The script is executed right before the actual docker image is started.  You could for example provide a script that builds the actual image right before running the tool on the VM.  It would be also possible to push the docker image to a private dockerhub repository and login to your docker account via this script. We provide two example template scripts in the cplex folder. Please note that in both cases you distribute the docker image with your cplex binary on all machines where you run the toolkit. If you login to dockerhub then your credentials will saved on the VM. If you are not the only docker user on the machine we do not recommend this approach! </p>"},{"location":"modules/metabolomics/#output","title":"Output","text":""},{"location":"modules/metabolomics/#gapseq-carveme","title":"GapSeq / CarveMe","text":"<p>Both tools are generating genome scale metabolic reconstruction models (<code>*.xml</code>).  All models are translated to json format and substrats, products and reactions are saved in distinct files.</p>"},{"location":"modules/metabolomics/#memote","title":"Memote","text":"<p>Memote tests metabolic reconstruction models and therefore produces a machine readable json file  (<code>*_report.json.gz</code>) and a human readable tsv (<code>*_metrics.tsv</code>) and html (<code>*_report.html</code>) file.</p>"},{"location":"modules/metabolomics/#smetana","title":"Smetana","text":"<p>Smetana is used for analysing possible interactions in microbial communities. Smetana's global and detailed modes  are executed per sample. The Smetana output is saved in <code>*_detailed.tsv</code> and <code>*_global.tsv</code>.</p>"},{"location":"modules/plasmids/","title":"Plasmids","text":"<p>The plasmid module is able to identify contigs as plasmids and also to assemble plasmids from the samples fastq data. The module is executed in two parts. In the first part contigs of a metagenome assembler are scanned for plasmids. In the second part a plasmid assembler is used to assemble circular plasmids out of raw reads. All plasmid detection tools are executed on the circular assembly result and on the contigs of the metagenome assembler. Just the filtered sequences are used for downstream analysis. </p> <p>The identification of plasmids is based on the combined result of tools which have a <code>filter</code> property assigned. Results of all tools that have the <code>filter</code> property set to true are combined either by a logical <code>OR</code> or by a logical <code>AND</code>. </p> <p>Example for the <code>OR</code> and <code>AND</code> operations:  Let's assume that we have three plasmid detection tools (t1, t2, t3) that have four contigs (c1, c2, c3, c4) as input. Let's further assume that c1 and c2 are detected by all tools as contigs and c3 and c4 are only detected by t1 and t2. By using an <code>AND</code> only c1 and c2 are finally reported by the module as plasmids. By using an <code>OR</code> all contigs would be annotated as plasmids. </p> <p>It is also possible to simply run a tool without using its result as filter by setting <code>filter</code> to <code>false</code>. If a tool should not be executed then the tool section should be removed. Only the detected plasmids will be used for downstream analysis.</p> <p>For running a plasmid assembly we suggest running the full pipeline mode with the enabled plasmids module. See input example configuration files. The read mapper can either be Bowtie or Bwa for Illumina and minimap for long reads.  </p>"},{"location":"modules/plasmids/#input","title":"Input","text":"CommandConfiguration file for full pipeline mode with plasmids detectionsConfiguration file for plasmids module onlyTSV Table <pre><code>-entry wPlasmidsPath -params-file example_params/plasmids.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the plasmids section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: true\ninput:\n  paired:\n    path: \"test_data/fullPipeline/reads_split.tsv\"\n    watch: false\noutput: \"output\"\nrunid: 1\nscratch: \"/vol/scratch\"\ndatabases: \"/mnt/databases/\"\nlogDir: log\npublishDirMode: \"symlink\"\nsteps:\n  qc:\n    interleaved: false\n    fastp:\n       # Example params: \" --cut_front --cut_tail --detect_adapter_for_pe  \"\n       additionalParams: \"  \"\n       timeLimit: \"AUTO\"\n  assembly:\n    megahit:\n      fastg: false\n      additionalParams: \" --min-contig-len 200 \"\n      resources:\n         RAM: \n            mode: 'DEFAULT'\n            predictMinLabel: 'AUTO' \n  binning:\n    bowtie:\n      additionalParams: \n        bowtie: \" --quiet --very-sensitive \"\n        samtoolsView: \" -F 3584 \" \n    contigsCoverage:\n      additionalParams: \"\"\n    genomeCoverage:\n      additionalParams: \" \"\n    metabat:\n      additionalParams: \"   \"\n  plasmid:\n    SCAPP:\n      additionalParams: \n        SCAPP: \"  \"\n        bowtie: \"  \"\n        coverm: \"  \"\n        covermONT: \"  \"\n        minimap: \" \"\n        samtoolsViewBowtie: \" -F 3584 \" \n        samtoolsViewMinimap: \" \" \n    ViralVerifyPlasmid:\n      filter: true\n      filterString: \"Uncertain - plasmid or chromosomal|Plasmid\"\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/pfam-A_35.0.hmm.gz\n          md5sum: c80b75bd48ec41760bbca19c70616e36\n      additionalParams: \" --thr 7 \"\n    MobTyper:\n      filter: true\n      minLength: 5000\n      additionalParams: \" --min_length 9000  \"\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/mob_20220929.gz\n          md5sum: 21fcaf9c3754a985d1d6875939d71e28\n    Platon:\n      filter: false\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/platon_20220929.tar.gz\n          md5sum: f6d1701704396182c6c9daca053eb9d6\n      additionalParams: \"   \"\n    PlasClass:\n      filter: true\n      threshold: 0.5 \n      additionalParams: \"   \"\n    Filter:\n      method: \"AND\"\n      minLength: 0 \n    PLSDB:\n      sharedKmerThreshold: 30\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/plasmids_plsdb_20220929.tar.bz2\n          md5sum: 13c1078e6cd6a46e3f508c24ca07cc18\n      additionalParams:\n        mashSketch: \" -S 42 -k 21 -s 1000 \"\n        mashDist: \" -v 0.2 -d 0.2 \"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the plasmids section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\ndatabases: \"/vol/scratch/databases/\"\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  plasmid:\n    input: \"test_data/plasmid/input_contigs.tsv\"\n    ViralVerifyPlasmid:\n      filter: true\n      filterString: \"Uncertain - plasmid or chromosomal|Plasmid\"\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/pfam-A_35.0.hmm.gz\n          md5sum: c80b75bd48ec41760bbca19c70616e36\n      additionalParams: \" --thr 7 \"\n    MobTyper:\n      filter: true\n      minLength: 5000\n      additionalParams: \" --min_length 9000  \"\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/mob_20220929.gz\n          md5sum: 21fcaf9c3754a985d1d6875939d71e28\n    Platon:\n      filter: false\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/platon_20220929.tar.gz\n          md5sum: f6d1701704396182c6c9daca053eb9d6\n      additionalParams: \"   \"\n    PlasClass:\n      filter: true\n      threshold: 0.5 \n      additionalParams: \"   \"\n    Filter:\n      method: \"AND\"\n      minLength: 0 \n    PLSDB:\n      sharedKmerThreshold: 30\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/plasmids_plsdb_20220929.tar.bz2\n          md5sum: 13c1078e6cd6a46e3f508c24ca07cc18\n      additionalParams:\n        mashSketch: \" -S 42 -k 21 -s 1000 \"\n        mashDist: \" -v 0.2 -d 0.2 \"\n\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>DATASET BIN_ID  PATH\ntest3   bin.1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa\ntest1   bin.2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa\ntest1   bin.8   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta\ntest2   bin.9   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta\ntest2   bin.32  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa\n</code></pre>"},{"location":"modules/plasmids/#databases","title":"Databases","text":"<p>The plasmid module needs the following compressed database file formats: </p>"},{"location":"modules/plasmids/#viralverifyplasmid","title":"ViralVerifyPlasmid","text":"<p>ViralVerifyPlasmid needs a recent pfam-A database in .gz format. See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_ViralVerifyPlasmid_ACCESS XXXXXXX\nnextflow secrets set S3_ViralVerifyPlasmid_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/plasmids/#mobtyper","title":"MobTyper","text":"<p>Database was generated by gzipping the output of mob_init. See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_MobTyper_ACCESS XXXXXXX\nnextflow secrets set S3_MobTyper_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/plasmids/#platon","title":"Platon","text":"<p>The tar gzipped database for running platon can be fetched from the Platon github page. See database section for possible download strategies. If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_Platon_ACCESS XXXXXXX\nnextflow secrets set S3_Platon_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/plasmids/#plsdb","title":"PLSDB","text":"<p>PLSDB Database is available via this link: https://ccb-microbe.cs.uni-saarland.de/plsdb/plasmids/download/plasmids_meta.tar.bz2. All files except .tsv and .msh were deleted from the compressed package. See database section for possible download strategies. The compressed database must be a tar.bz2 file.  If you need credentials to access your files via S3 then please use the following command:</p> <pre><code>nextflow secrets set S3_PLSDB_ACCESS XXXXXXX\nnextflow secrets set S3_PLSDB_SECRET XXXXXXX\n</code></pre>"},{"location":"modules/plasmids/#output","title":"Output","text":""},{"location":"modules/plasmids/#scapp","title":"SCAPP","text":"<p>SCAPP detects plasmid sequences out of the samples assembly graph. It reports sequences as gzipped fasta files (<code>*_plasmids.fasta.gz</code>). A basic statistic (<code>*_plasmids_stats.tsv</code>) per plasmid and a summary statistic (<code>*_plasmids_summary_stats.tsv</code>) over all plasmids is also generated. Coverm coverage metrics are generated for all plasmids. Gene coverage values are generated as part of the annotation module output.</p>"},{"location":"modules/plasmids/#plasclass","title":"PlasClass","text":"<p>PlasClass is able to identify plasmids by using a statistical model that was build using kmer frequencies. It reports gzipped fata files and their probabilities (<code>*_plasclass.tsv</code>).</p>"},{"location":"modules/plasmids/#mobtyper-and-platon","title":"MobTyper and Platon","text":"<p>MobTyper and Platon are using both replicon typing for plasmid detection. (<code>*_mobtyper_results.tsv</code>, <code>*_platon.tsv</code>)</p>"},{"location":"modules/plasmids/#viralverifyplasmid_1","title":"ViralVerifyPlasmid","text":"<p>ViralVerfiy is applying a Naive Bayes classifier (<code>*_viralverifyplasmid.tsv</code>).</p>"},{"location":"modules/plasmids/#plsdb_1","title":"PLSDB","text":"<p>PLSDB includes a curated set of plasmid sequences that were extracted from databases like refseq. The metadata of found sequences are reported in <code>*.tsv</code> and the metadata of the filtered sequences in <code>*_kmerThreshold_X.tsv</code>.</p>"},{"location":"modules/qualityControl/","title":"Quality Control","text":"<p>The quality control module removes adapters, trims and filters short read and long read data.</p>"},{"location":"modules/qualityControl/#input","title":"Input","text":"Command for short read dataConfiguration FileCommand for nanopore dataTSV Table short readTSV Table nanopore <pre><code>-entry wShortReadQualityControl -params-file example_params/qc.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the quality control section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\ndatabases: \"/mnt/databases\"\nlogLevel: 1\nscratch: \"/vol/scratch\"\nsteps:\n  qc:\n    input: \"test_data/qc/reads_split.tsv\"\n    fastp:\n       # Example params: \" --cut_front --cut_tail --detect_adapter_for_pe  \"\n       additionalParams: \"  \"\n    filterHuman:\n      additionalParams: \"  \"\n      database:\n        download:\n          source: https://openstack.cebitec.uni-bielefeld.de:8080/databases/human_filter.db.20231218v2.gz\n          md5sum: cc92c0f926656565b1156d66a0db5a3c\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>-entry wOntQualityControl -params-file example_params/qcONT.yml\n</code></pre> <pre><code>SAMPLE  READS1  READS2\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read2_1.fq.gz\ntest2   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read1_1.fq.gz  https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/read2_1.fq.gz\n</code></pre> <pre><code>SAMPLE  READS\nnano    https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/SRR16328449_qc.fq.gz\n</code></pre>"},{"location":"modules/qualityControl/#output","title":"Output","text":"<p>The output is a gzipped fastq file (short read: <code>SAMPLE_interleaved.qc.fq.gz</code>, long read: <code>SAMPLE_qc.fq.gz</code>) containing trimmed and quality filtered reads.</p>"},{"location":"modules/readMapping/","title":"Read Mapping","text":"<p>Note: This module only supports illumina data. </p>"},{"location":"modules/readMapping/#input","title":"Input","text":"CommandConfiguration FileMAGs TSV TableSamples TSV Table <pre><code>-entry wReadMapping -params-file example_params/readMapping.yml\n</code></pre> <p>Warning</p> <p>The configuration file shown here is for demonstration and testing purposes only.    Parameters that should be used in production can be viewed in the read mapping section    of one of the yaml files located in the <code>default</code> folder of the Toolkit's Github repository.</p> <pre><code>tempdir: \"tmp\"\nsummary: false\ns3SignIn: false\noutput: \"output\"\nlogDir: log\nrunid: 1\nlogLevel: 1\nscratch: \"/vol/scratch\"\npublishDirMode: \"symlink\"\nsteps:\n  readMapping:\n    samples: \n       paired: test_data/readMapping/samples.tsv\n       single: test_data/readMapping/single.tsv\n       ont: test_data/readMapping/ont.tsv\n    mags: test_data/readMapping/mags.tsv\n    bwa2:\n      additionalParams:\n        bwa2_index: \"\"\n        bwa2_mem: \"\"\n    minimap:\n      additionalParams:\n        minimap_index: \"\"\n        minimap: \"\"\n\n    coverm: \" --min-covered-fraction 0 \"\n    covermONT: \" --min-covered-fraction 0 \"\nresources:\n  highmemLarge:\n    cpus: 28\n    memory: 230\n  highmemMedium:\n    cpus: 14\n    memory: 113\n  large:\n    cpus: 28\n    memory: 58\n  medium:\n    cpus: 14\n    memory: 29\n  small:\n    cpus: 7\n    memory: 14\n  tiny:\n    cpus: 1\n    memory: 1\n</code></pre> <pre><code>BINS\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.1.fa\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.2.fa\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.8.fasta\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.9.fasta\nhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/bins/bin.32.fa\n</code></pre> <pre><code>SAMPLE  READS\ntest1   https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/meta_test/small/interleaved.fq.gz\n</code></pre>"},{"location":"modules/readMapping/#output","title":"Output","text":"<p>The produced output files are the following: count.tsv, mean.tsv, mean_mincov10.tsv, rpkm.tsv, tpm.tsv, trimmed_mean.tsv. The content of the files are produced by coverm. All metrics are explained on the coverm GitHub page: https://github.com/wwood/CoverM .</p>"}]}